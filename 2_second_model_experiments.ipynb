{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Second model experiments\n",
    "\n",
    "This second model is a direct influence of the **first model**, which uses a stacking architecture with a label selection that takes place between the first and the second level of binary classifiers. This label selection uses the **F-test** to select the most relevant labels that will be used as _features_ in the second level.\n",
    "\n",
    "Since the initial results of this model are quite interesting, I had this ideia of using the same concept, but for a **classifier chain** architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.dataset import load_dataset, available_data_sets\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingWithFTests(ProblemTransformationBase):\n",
    "    alpha: float\n",
    "    use_first_layer_to_calculate_correlations: bool\n",
    "\n",
    "    first_layer_classifiers: BinaryRelevance\n",
    "    # TODO should be any generic type of classifier\n",
    "    second_layer_classifiers: List[Any]\n",
    "    labels_count: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: float = 0.5,\n",
    "        classifier: Any = None,\n",
    "        require_dense: Optional[List[bool]] = None\n",
    "    ):\n",
    "        super(StackingWithFTests, self).__init__(classifier, require_dense)\n",
    "\n",
    "        if alpha < 0.0 or alpha > 1.0:\n",
    "            raise Exception(\"alpha must be >= 0.0 and <= 1.0\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.first_layer_classifiers = BinaryRelevance(\n",
    "            classifier=SVC(),\n",
    "            require_dense=[False, True]\n",
    "        )\n",
    "        # TODO: allow for any base model (base classifier) to be used\n",
    "        # right now I am forcing the use of SVC\n",
    "\n",
    "        self.second_layer_classifiers = []\n",
    "        self.correlated_labels_map = pd.DataFrame()\n",
    "        self.labels_count = 0\n",
    "\n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.labels_count = y.shape[1]\n",
    "\n",
    "        self.first_layer_classifiers.fit(X, y)\n",
    "\n",
    "        label_classifications = y\n",
    "        if self.use_first_layer_to_calculate_correlations:\n",
    "            label_classifications = self.first_layer_classifiers.predict(X)\n",
    "\n",
    "        f_tested_label_pairs = self.calculate_f_test_for_all_label_pairs(\n",
    "            label_classifications)\n",
    "        \n",
    "        self.correlated_labels_map = self.get_map_of_correlated_labels(\n",
    "            f_tested_label_pairs)\n",
    "\n",
    "        for i in range(self.labels_count):\n",
    "            mask = self.correlated_labels_map[\"for_label\"] == i\n",
    "            split_df = self.correlated_labels_map[mask].reset_index(drop=True)\n",
    "            labels_to_expand = split_df[\"expand_this_label\"].to_list()\n",
    "\n",
    "            additional_input = label_classifications.todense()[\n",
    "                :, labels_to_expand]\n",
    "\n",
    "            X_expanded = np.hstack([X.todense(), additional_input])\n",
    "            X_expanded = np.asarray(X_expanded)\n",
    "\n",
    "            y_label_specific = y.todense()[:, i]\n",
    "            y_label_specific = self.convert_matrix_to_vector(y_label_specific)\n",
    "\n",
    "            meta_classifier = SVC()\n",
    "            meta_classifier.fit(X_expanded, y_label_specific)\n",
    "\n",
    "            self.second_layer_classifiers.append(meta_classifier)\n",
    "            print(f\"finished training meta classifier for label {i}\")\n",
    "\n",
    "    def calculate_f_test_for_all_label_pairs(self, label_classifications: Any) -> List[Dict[str, Any]]:\n",
    "        results = []\n",
    "\n",
    "        for i in range(0, self.labels_count):\n",
    "            for j in range(0, self.labels_count):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                X = label_classifications.todense()[:, i]\n",
    "                base_label = self.convert_matrix_to_array(X)\n",
    "\n",
    "                y = label_classifications.todense()[:, j]\n",
    "                against_label = self.convert_matrix_to_vector(y)\n",
    "\n",
    "                f_test_result = f_classif(base_label, against_label)[0]\n",
    "\n",
    "                results.append({\n",
    "                    \"label_being_tested\": i,\n",
    "                    \"against_label\": j,\n",
    "                    \"f_test_result\": float(f_test_result)\n",
    "                })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def convert_matrix_to_array(self, matrix: Any):\n",
    "        return np.asarray(matrix).reshape(-1, 1)\n",
    "\n",
    "    def convert_matrix_to_vector(self, matrix: Any):\n",
    "        return np.asarray(matrix).reshape(-1)\n",
    "\n",
    "    def get_map_of_correlated_labels(self, f_test_results: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "        temp_df = pd.DataFrame(f_test_results)\n",
    "\n",
    "        sorted_temp_df = temp_df.sort_values(\n",
    "            by=[\"label_being_tested\", \"f_test_result\"],\n",
    "            ascending=[True, False])\n",
    "        # ordering in descending order by the F-test result,\n",
    "        # following what the main article describes\n",
    "\n",
    "        selected_features = []\n",
    "\n",
    "        for i in range(0, self.labels_count):\n",
    "            mask = sorted_temp_df[\"label_being_tested\"] == i\n",
    "            split_df = sorted_temp_df[mask].reset_index(drop=True)\n",
    "\n",
    "            big_f = split_df[\"f_test_result\"].sum()\n",
    "            max_cum_f = self.alpha * big_f\n",
    "\n",
    "            cum_f = 0\n",
    "            for _, row in split_df.iterrows():\n",
    "                cum_f += row[\"f_test_result\"]\n",
    "                if cum_f > max_cum_f:\n",
    "                    break\n",
    "\n",
    "                selected_features.append({\n",
    "                    \"for_label\": i,\n",
    "                    \"expand_this_label\": int(row[\"against_label\"]),\n",
    "                    \"f_test_result\": float(row[\"f_test_result\"]),\n",
    "                })\n",
    "\n",
    "        cols = [\"for_label\", \"expand_this_label\", \"f_test_result\"]\n",
    "        return pd.DataFrame(selected_features, columns=cols)\n",
    "\n",
    "    def predict(self, X: Any) -> np.ndarray[Any, Any]:\n",
    "        if self.correlated_labels_map.columns.size == 0:\n",
    "            raise Exception(\"model was not trained yet\")\n",
    "\n",
    "        predictions = self.first_layer_classifiers.predict(X)\n",
    "        local_labels_count = predictions.shape[1]\n",
    "\n",
    "        second_layer_predictions = []\n",
    "\n",
    "        for i in range(local_labels_count):\n",
    "            mask = self.correlated_labels_map[\"for_label\"] == i\n",
    "            split_df = self.correlated_labels_map[mask].reset_index(drop=True)\n",
    "            labels_to_expand = split_df[\"expand_this_label\"].to_list()\n",
    "\n",
    "            additional_input = predictions.todense()[:, labels_to_expand]\n",
    "\n",
    "            X_expanded = np.hstack([X.todense(), additional_input])\n",
    "            X_expanded = np.asarray(X_expanded)\n",
    "\n",
    "            temp_preds = self.second_layer_classifiers[i].predict(X_expanded)\n",
    "            second_layer_predictions.append(temp_preds)\n",
    "\n",
    "        reshaped_array = np.asarray(second_layer_predictions).T\n",
    "        return reshaped_array\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
