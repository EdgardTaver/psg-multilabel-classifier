{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Second model experiments\n",
    "\n",
    "This second model is a direct influence of the **first model**, which uses a stacking architecture with a label selection that takes place between the first and the second level of binary classifiers. This label selection uses the **F-test** to select the most relevant labels that will be used as _features_ in the second level.\n",
    "\n",
    "Since the initial results of this model are quite interesting, I had this ideia of using the same concept, but for a **classifier chain** architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.dataset import load_dataset, available_data_sets\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Baseline model\n",
    "\n",
    "The baseline model will be the default **Classifier Chain** available in [the scikit-multilearn package](http://scikit.ml/api/skmultilearn.problem_transform.cc.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "Accuracy score:  0.6780936454849499\n",
      "Hamming loss:  0.09085841694537347\n"
     ]
    }
   ],
   "source": [
    "train_data = load_dataset(\"scene\", \"train\")\n",
    "test_data = load_dataset(\"scene\", \"test\")\n",
    "# let's use the same \"scene\" dataset, that was used in the previous notebook (`1_first_model_experiments.ipynb`)\n",
    "\n",
    "X_train, y_train, _, _ = train_data\n",
    "X_test, y_test, _, _ = test_data\n",
    "\n",
    "classifier = ClassifierChain(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "baseline_cc_accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "baseline_cc_hamming_loss = metrics.hamming_loss(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy score: \", baseline_cc_accuracy)\n",
    "print(\"Hamming loss: \", baseline_cc_hamming_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking this baseline classifier chain implementation, and also the same dataset, let's check if using the **F-test** to order the classifiers will result in better scores.\n",
    "\n",
    "Something that should be mentioned is that this is _already better_ than the **Stacking With F-test**.\n",
    "\n",
    "The documentation for this `ClassifierChain` class states that \"for L labels it trains L classifiers ordered in a chain according to the **Bayesian chain rule**\". However, the source code shows nothing about this... The ordering is a very simple sequential list of how the labels are already organized in the training data. Here is the code:\n",
    "\n",
    "```python\n",
    "# class ClassifierChain(ProblemTransformationBase):\n",
    "# ...\n",
    "    def _order(self):\n",
    "        if self.order is not None:\n",
    "            return self.order\n",
    "\n",
    "        try:\n",
    "            return list(range(self._label_count))\n",
    "        except AttributeError:\n",
    "            raise NotFittedError(\"This Classifier Chain has not been fit yet\")\n",
    "```\n",
    "\n",
    "So, the ordering is just the order of the labels in the dataset. This is weird. Anyway, the good thing is that we can use this `ClassifierChain` as the base class for our implementation, and simply pass a custom ordering to it.\n",
    "\n",
    "Something else to consider, however, is that it will simply iterate over the classifiers following the order we pass to it. I was thinking of something akin to a graph, where the path taken in the chain would be dependant on the output of the previous classifier (instead of simply accumulating the predictions of all classifiers). For instance:\n",
    "\n",
    "* The start of the chain is the label `l1`.\n",
    "* For a given instance, it predicts `l1 = 1`. Then take a path towards `l2`, with which it has a high correlation according to the **F-test**.\n",
    "* For another instance, it predicts `l1 = 0`. Then take a path towards `l3`, with which it has no correlation, according to the **F-test**.\n",
    "\n",
    "This would be more similar to what is done in the stacking method.\n",
    "\n",
    "It is something to consider, but for now, let's just use the default implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "class ClassifierChainWithFTests(ProblemTransformationBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: float = 0.5,\n",
    "        classifier: Any = None,\n",
    "        require_dense: Optional[List[bool]] = None\n",
    "    ):\n",
    "        super(ClassifierChainWithFTests, self).__init__(classifier, require_dense)\n",
    "\n",
    "        if alpha < 0.0 or alpha > 1.0:\n",
    "            raise Exception(\"alpha must be >= 0.0 and <= 1.0\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.correlated_labels_map = pd.DataFrame()\n",
    "        self.labels_count = 0\n",
    "\n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.labels_count = y.shape[1]\n",
    "\n",
    "        f_tested_label_pairs = self.calculate_f_test_for_all_label_pairs(\n",
    "            label_classifications)\n",
    "        \n",
    "        self.correlated_labels_map = self.get_map_of_correlated_labels(\n",
    "            f_tested_label_pairs)\n",
    "\n",
    "        # TODO: should extract ordering from it\n",
    "\n",
    "        return self.correlated_labels_map\n",
    "\n",
    "    def calculate_f_test_for_all_label_pairs(self, label_classifications: Any) -> List[Dict[str, Any]]:\n",
    "        results = []\n",
    "\n",
    "        for i in range(0, self.labels_count):\n",
    "            for j in range(0, self.labels_count):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                X = label_classifications.todense()[:, i]\n",
    "                base_label = self.convert_matrix_to_array(X)\n",
    "\n",
    "                y = label_classifications.todense()[:, j]\n",
    "                against_label = self.convert_matrix_to_vector(y)\n",
    "\n",
    "                f_test_result = f_classif(base_label, against_label)[0]\n",
    "\n",
    "                results.append({\n",
    "                    \"label_being_tested\": i,\n",
    "                    \"against_label\": j,\n",
    "                    \"f_test_result\": float(f_test_result)\n",
    "                })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def convert_matrix_to_array(self, matrix: Any):\n",
    "        return np.asarray(matrix).reshape(-1, 1)\n",
    "\n",
    "    def convert_matrix_to_vector(self, matrix: Any):\n",
    "        return np.asarray(matrix).reshape(-1)\n",
    "\n",
    "    def get_map_of_correlated_labels(self, f_test_results: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "        temp_df = pd.DataFrame(f_test_results)\n",
    "\n",
    "        sorted_temp_df = temp_df.sort_values(\n",
    "            by=[\"label_being_tested\", \"f_test_result\"],\n",
    "            ascending=[True, False])\n",
    "        # ordering in descending order by the F-test result,\n",
    "        # following what the main article describes\n",
    "\n",
    "        selected_features = []\n",
    "\n",
    "        for i in range(0, self.labels_count):\n",
    "            mask = sorted_temp_df[\"label_being_tested\"] == i\n",
    "            split_df = sorted_temp_df[mask].reset_index(drop=True)\n",
    "\n",
    "            big_f = split_df[\"f_test_result\"].sum()\n",
    "            max_cum_f = self.alpha * big_f\n",
    "\n",
    "            cum_f = 0\n",
    "            for _, row in split_df.iterrows():\n",
    "                cum_f += row[\"f_test_result\"]\n",
    "                if cum_f > max_cum_f:\n",
    "                    break\n",
    "\n",
    "                selected_features.append({\n",
    "                    \"for_label\": i,\n",
    "                    \"expand_this_label\": int(row[\"against_label\"]),\n",
    "                    \"f_test_result\": float(row[\"f_test_result\"]),\n",
    "                })\n",
    "\n",
    "        cols = [\"for_label\", \"expand_this_label\", \"f_test_result\"]\n",
    "        return pd.DataFrame(selected_features, columns=cols)\n",
    "\n",
    "    def predict(self, X: Any) -> np.ndarray[Any, Any]:\n",
    "        # TODO: implement\n",
    "        return np.zeros((X.shape[0], self.labels_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
