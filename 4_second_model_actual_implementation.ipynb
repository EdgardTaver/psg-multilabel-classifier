{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual implementation of the second model\n",
    "\n",
    "Now we will really implement the proposed second model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support import CalculateLabelsCorrelationWithFTest\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import Any, List\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.base import MLClassifierBase\n",
    "from sklearn.svm import SVC\n",
    "from evaluation import EvaluationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:undivided - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "full_data = load_dataset(\"scene\", \"undivided\")\n",
    "X_full, y_full, _, _ = full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 1, 0, 2, 3]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_chain_based_on_f_test(res):\n",
    "    chain = []\n",
    "    sorted_res = res.sort_values(by=[\"f_test_result\"], ascending=False)\n",
    "    \n",
    "    element = int(sorted_res.iloc[0][\"for_label\"])\n",
    "    chain.append(element)\n",
    "\n",
    "    m = ~sorted_res[\"expand_this_label\"].isin(chain)\n",
    "    m &= sorted_res[\"for_label\"] == element\n",
    "    \n",
    "    while m.sum() > 0:\n",
    "        sliced_res = sorted_res[m]\n",
    "        sorted_sliced_res = sliced_res.sort_values(by=[\"f_test_result\"], ascending=False)\n",
    "\n",
    "        element = int(sorted_sliced_res.iloc[0][\"expand_this_label\"])\n",
    "        chain.append(element)\n",
    "\n",
    "        m = ~sorted_res[\"expand_this_label\"].isin(chain)\n",
    "        m &= sorted_res[\"for_label\"] == element\n",
    "    \n",
    "    return chain\n",
    "\n",
    "build_chain_based_on_f_test(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChainWithFTestOrdering(MLClassifierBase):\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: float = 0.5,\n",
    "        base_classifier: Any = SVC(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.order = []\n",
    "        self.main_classifier = None\n",
    "        self.copyable_attrs = [\"base_classifier\", \"alpha\"]\n",
    "        # NOTE: this `copyable_attrs` must match exactly the arguments passed to the constructor\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.base_classifier = base_classifier\n",
    "\n",
    "        self.calculator = CalculateLabelsCorrelationWithFTest(alpha=self.alpha)        \n",
    "    \n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.classes_ = np.arange(y.shape[1])\n",
    "        # NOTE: this is required to run the evaluation pipeline\n",
    "        \n",
    "        self.order = build_chain_based_on_f_test(self.calculator.get(y))\n",
    "        \n",
    "        self.main_classifier = ClassifierChain(\n",
    "            classifier=self.base_classifier,\n",
    "            require_dense=[False, True],\n",
    "            order=self.order,\n",
    "        )\n",
    "\n",
    "        self.main_classifier.fit(X, y)\n",
    "    \n",
    "    def predict(self, X: Any):\n",
    "        return self.main_classifier.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierChainWithFTestOrdering(alpha=1)\n",
    "pipe = EvaluationPipeline(model)\n",
    "result = pipe.run(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1883 ± 0.13\n",
      "Hamming Loss: -0.2692 ± 0.05\n"
     ]
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions so far\n",
    "\n",
    "* The bad results, observed in the previous Jupyter notebooks, were observed again, which is actually good and expected.\n",
    "* It was a bit hard, at first, to comply with the `base_classifier` interface that the evaluation pipeline requires (as it is based on the `cross_validate` function from **scikit**). Main learnis:\n",
    "  * Your classifier class must set a `copyable_attrs` property, which must match exactly the arguments of the `__init__` method (the constructor of _your_ class).\n",
    "  * You must also set a `classes_` property, which should be a list of the possible classes that your classifier can predict. You can obtain this list from the `y` argument of the `fit` method, by doing this: `self.classes_ = np.arange(y.shape[1])` (at least in the case of multi-label classification)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
