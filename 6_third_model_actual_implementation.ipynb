{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import pygad\n",
    "from typing import List\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Any, Optional\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_duplicates(int_list: List[int]) -> bool:\n",
    "    seen = set()\n",
    "    for num in int_list:\n",
    "        if num in seen:\n",
    "            return True\n",
    "        seen.add(num)\n",
    "    return False\n",
    "\n",
    "def has_negatives(int_list: List[int]) -> bool:\n",
    "    for num in int_list:\n",
    "        if num < 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithmForMultiLabel:\n",
    "    def __init__(self, base_classifier: Any, num_generations: int = 5, random_state: Optional[int] = None) -> None:\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_generations = num_generations\n",
    "\n",
    "        if random_state is None:\n",
    "            self.random_state = np.random.randint(0, 1000)\n",
    "        else:\n",
    "            self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.x = X\n",
    "        self.y = y\n",
    "        # this is the most practical way to pass the data to the fitness function\n",
    "\n",
    "        label_count = self.y.shape[1]\n",
    "        if label_count < 3:\n",
    "            raise Exception(\"label count is too low, we need at least 3 labels\")\n",
    "\n",
    "        label_space = np.arange(label_count)\n",
    "        solutions_per_population = math.ceil(label_count / 2)\n",
    "        # to simplify the model, some heuristics are used\n",
    "\n",
    "        ga_model = pygad.GA( #type:ignore\n",
    "            gene_type=int,\n",
    "            gene_space=label_space,\n",
    "            random_seed=self.random_state,\n",
    "            save_best_solutions=False,\n",
    "            fitness_func=self.model_fitness_func,\n",
    "            allow_duplicate_genes=False, # very important, otherwise we will have duplicate labels in the ordering\n",
    "            num_genes=label_count,\n",
    "\n",
    "            # set up\n",
    "            num_generations=self.num_generations,\n",
    "            sol_per_pop=solutions_per_population,\n",
    "\n",
    "            # following what the article describes\n",
    "            keep_elitism=1, # also following what the article describes, but we have to double check [TODO]\n",
    "            parent_selection_type=\"rws\", # following what the article describes\n",
    "            # mutation_probability=0.005, # following what the article describes\n",
    "\n",
    "            # the following settings are fixed\n",
    "            # they were chosen for no particular reason\n",
    "            # they are being kept as fixed to simplify the model\n",
    "            num_parents_mating=2,\n",
    "            crossover_type=\"scattered\",\n",
    "            mutation_type=\"random\",\n",
    "            mutation_by_replacement=True,\n",
    "            mutation_num_genes=1,\n",
    "        )\n",
    "\n",
    "        ga_model.run()\n",
    "\n",
    "        solution, _, _ = ga_model.best_solution()\n",
    "\n",
    "        best_classifier = ClassifierChain(\n",
    "            classifier=copy.deepcopy(self.base_classifier),\n",
    "            require_dense=[False, True],\n",
    "            order=solution,\n",
    "        )\n",
    "\n",
    "        best_classifier.fit(self.x, self.y)\n",
    "        return best_classifier\n",
    "        \n",
    "    def model_fitness_func(self, ga_instance: Any, solution: Any, solution_idx: Any) -> float:\n",
    "        if has_duplicates(solution):\n",
    "            print(\"solutions contains duplicated values, skipping\")\n",
    "            return 0\n",
    "        \n",
    "        if has_negatives(solution):\n",
    "            print(\"solutions contains negative values, skipping\")\n",
    "            return 0\n",
    "\n",
    "        hamming_loss = self.test_ordering(solution)\n",
    "        hamming_loss = float(hamming_loss)\n",
    "        return 1/hamming_loss\n",
    "        # this will be the fitness function result, and we want to maximize it\n",
    "        # therefore, we have to return the inverse of the hamming loss\n",
    "    \n",
    "    def test_ordering(self, solution: List[int]):\n",
    "        print(f\"testing order: {solution}\")\n",
    "\n",
    "        classifier = ClassifierChain(\n",
    "            classifier=copy.deepcopy(self.base_classifier),\n",
    "            require_dense=[False, True],\n",
    "            order=solution,\n",
    "        )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.x, self.y, test_size=0.2, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        preds = classifier.predict(X_test)\n",
    "\n",
    "        return metrics.hamming_loss(y_test, preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing order: [5 2 4 0 1 3]\n",
      "testing order: [2 3 1 5 0 4]\n",
      "testing order: [1 0 4 2 3 5]\n",
      "testing order: [2 3 0 1 5 4]\n",
      "testing order: [2 3 4 5 1 0]\n",
      "testing order: [2 3 0 1 5 4]\n",
      "testing order: [2 3 4 5 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=RandomForestClassifier(random_state=456),\n",
       "                order=array([1, 0, 4, 2, 3, 5]), require_dense=[False, True])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = GeneticAlgorithmForMultiLabel(\n",
    "    base_classifier=RandomForestClassifier(random_state=456),\n",
    "    num_generations=1,\n",
    "    random_state=123,\n",
    ")\n",
    "r = m.fit(datasets[\"scene\"][\"X_train\"], datasets[\"scene\"][\"y_train\"])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2568283166109253\n",
      "0.13486096370513379\n"
     ]
    }
   ],
   "source": [
    "preds = r.predict(datasets[\"scene\"][\"X_test\"])\n",
    "\n",
    "print(metrics.hamming_loss(datasets[\"scene\"][\"y_test\"], preds))\n",
    "print(metrics.f1_score(datasets[\"scene\"][\"y_test\"], preds, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
