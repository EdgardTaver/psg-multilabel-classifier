{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation pipeline\n",
    "\n",
    "The initial results for the second model are quite mixed. Actually, they are quite bad in general. But it is a bit hard to understand why its performance is so bad without having a proper evaluation pipeline, that should use cross-validation as a way to mitigate the effects of the randomness of the train-test split.\n",
    "\n",
    "## 3.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Any, Dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "full_data = load_dataset(\"scene\", \"undivided\")\n",
    "train_data = load_dataset(\"scene\", \"train\")\n",
    "test_data = load_dataset(\"scene\", \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<1211x294 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 351805 stored elements in List of Lists format>,\n",
       " <1211x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1286 stored elements in List of Lists format>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<1196x294 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 347724 stored elements in List of Lists format>,\n",
       " <1196x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 1299 stored elements in List of Lists format>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<2407x294 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 699529 stored elements in List of Lists format>,\n",
       " <2407x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2585 stored elements in List of Lists format>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data[:2])\n",
    "display(test_data[:2])\n",
    "display(full_data[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a side note here: this dataset is clearly too small. It might explain the wild results we were getting in the second model..\n",
    "\n",
    "Anyway, let's keep going forward with the evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, y_full, _, _ = full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_X_full = X_full.toarray()\n",
    "dense_y_full = y_full.toarray()\n",
    "\n",
    "\n",
    "skf = KFold(n_splits=5)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(dense_X_full, dense_y_full)):\n",
    "    X_train = dense_X_full[train_index]\n",
    "    y_train = dense_y_full[train_index]\n",
    "\n",
    "    X_test = dense_X_full[test_index]\n",
    "    y_test = dense_y_full[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**: `StratifiedKFold` **cannot** be used as it does not support multilabel ([source](https://stackoverflow.com/questions/48508036/sklearn-stratifiedkfold-valueerror-supported-target-types-are-binary-mul)).\n",
    "\n",
    "Instead of trying to set up everything by myself, let's use something that Scikit already provides: the `cross_validate` function, as described [here](https://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassifierChain(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "\n",
    "s = {\"accuracy\": make_scorer(metrics.accuracy_score),\n",
    "     \"hamming_loss\": make_scorer(metrics.hamming_loss, greater_is_better=False)}\n",
    "\n",
    "r = cross_validate(clf, X_full, y_full, cv=5, scoring=s, return_train_score=True)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6319200144926287, 0.06657267886278025)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"test_accuracy\"].mean(), r[\"test_accuracy\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.11195857523658352, 0.023752236934311968)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[\"test_hamming_loss\"].mean(), r[\"test_hamming_loss\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.06053257, 4.29102755, 3.58891082, 4.0080204 , 3.63190055]),\n",
       " 'score_time': array([0.65458941, 0.65905857, 0.6446743 , 0.67406464, 0.62596703]),\n",
       " 'test_accuracy': array([0.1473029 , 0.39626556, 0.05613306, 0.28274428, 0.3035343 ]),\n",
       " 'train_accuracy': array([0.31324675, 0.20727273, 0.3556594 , 0.26272066, 0.27050883]),\n",
       " 'test_hamming_loss': array([-0.28284924, -0.20020747, -0.31185031, -0.23354123, -0.22903673]),\n",
       " 'train_hamming_loss': array([-0.22995671, -0.26554113, -0.21581862, -0.25034614, -0.24575978])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick testing, using the proposed order based on F-test\n",
    "\n",
    "clf2 = ClassifierChain(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True],\n",
    "    order=[3, 0, 2, 5, 4, 1]\n",
    ")\n",
    "\n",
    "s2 = {\"accuracy\": metrics.make_scorer(metrics.accuracy_score),\n",
    "      \"hamming_loss\": metrics.make_scorer(metrics.hamming_loss, greater_is_better=False)}\n",
    "\n",
    "r2 = cross_validate(clf2, X_full, y_full, cv=5,\n",
    "                   scoring=s2, return_train_score=True)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the initial results here show that the proposed Classifier Chain is indeed **consistently bad**. Regardless, now I have a better ideia of how to set up this evaluation pipeline, which I should conclude tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Evaluation pipeline implementation\n",
    "\n",
    "The idea is to have a class with a `run()` method that will use a set of parameters and metrics that all modes in this work should use.\n",
    "\n",
    "For now, this pipeline will be described directly in this notebook. But I plan to move it to a `.py` file of its own to then use in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationPipelineResult:\n",
    "    cross_validate_result: Dict[Any, Any]\n",
    "\n",
    "    def __init__(self, cross_validate_result: Dict[Any, Any]) -> None:\n",
    "        self.cross_validate_result = cross_validate_result\n",
    "    \n",
    "    def describe(self) -> None:\n",
    "        print(\"Accuracy: {:.4f} ± {:.2f}\".format(\n",
    "            self.cross_validate_result[\"test_accuracy\"].mean(),\n",
    "            self.cross_validate_result[\"test_accuracy\"].std()\n",
    "        ))\n",
    "\n",
    "        print(\"Hamming Loss: {:.4f} ± {:.2f}\".format(\n",
    "            self.cross_validate_result[\"test_hamming_loss\"].mean(),\n",
    "            self.cross_validate_result[\"test_hamming_loss\"].std()\n",
    "        ))\n",
    "    \n",
    "    def raw(self) -> Dict[Any, Any]:\n",
    "        return self.cross_validate_result\n",
    "\n",
    "class EvaluationPipeline:\n",
    "    model: Any\n",
    "    n_folds: int\n",
    "\n",
    "    def __init__(self, model: Any, n_folds: int = 5) -> None:\n",
    "        # TODO: establish the model type\n",
    "        self.model = model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def run(self, X: Any, y: Any) -> EvaluationPipelineResult:\n",
    "        accuracy_scorer = metrics.make_scorer(metrics.accuracy_score)\n",
    "        hamming_loss_scorer = metrics.make_scorer(\n",
    "            metrics.hamming_loss, greater_is_better=False)\n",
    "\n",
    "        scoring_set = {\n",
    "            \"accuracy\": accuracy_scorer,\n",
    "            \"hamming_loss\": hamming_loss_scorer,\n",
    "        }\n",
    "\n",
    "        validate_result = cross_validate(\n",
    "            self.model,\n",
    "            X, y,\n",
    "            cv=self.n_folds,\n",
    "            scoring=scoring_set,\n",
    "            return_train_score=True)\n",
    "\n",
    "        return EvaluationPipelineResult(validate_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2563 ± 0.12\n",
      "Hamming Loss: -0.2482 ± 0.04\n"
     ]
    }
   ],
   "source": [
    "clf3 = ClassifierChain(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True],\n",
    "    order=[1, 3, 2, 5, 4, 0] # whatever order\n",
    ")\n",
    "\n",
    "evaluation_pipeline = EvaluationPipeline(clf3)\n",
    "result = evaluation_pipeline.run(X_full, y_full)\n",
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([4.27550077, 4.38973761, 3.88086176, 3.95994496, 3.68254423]),\n",
       " 'score_time': array([0.73751068, 0.69558883, 0.63721609, 0.70021701, 0.63118529]),\n",
       " 'test_accuracy': array([0.13900415, 0.38381743, 0.1039501 , 0.28274428, 0.37214137]),\n",
       " 'train_accuracy': array([0.3225974 , 0.22597403, 0.36137072, 0.28089304, 0.28504673]),\n",
       " 'test_hamming_loss': array([-0.28181189, -0.20746888, -0.3000693 , -0.23769924, -0.21413721]),\n",
       " 'train_hamming_loss': array([-0.22649351, -0.2578355 , -0.21183801, -0.24048114, -0.23901004])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.raw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
