{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Finding a stable base classifier\n",
    "\n",
    "## 11.1. Context\n",
    "\n",
    "All multi label classifiers require a base classifier, which is a regular binary classifier.\n",
    "\n",
    "Throughout the development of this project, however, is was noted that some of these regular binary classifier present specific behaviors:\n",
    "* The `SVC`, as shown in the notebook `8` (in which I debugged why the basic stacking was no different to the regular Binary Relevance, in spite of using more features), is **apparently insensitive to additional features** (these features being the predicted labels) and also **insensitive to different random states**.\n",
    "  * This makes it not suitable as the `SVC` ends up **discarding any information regarding label correlations**.\n",
    "  * Also, since changing the random state makes no different, it is probable that the base classifier is getting to some kind of **local minimum**.\n",
    "    * Perhaps tunning the parameters of the `SVC` can solve this. However, this is not the focus of this project. I much prefer to have a very basic base classifier that works out-of-the-box.\n",
    "* The `RandomForestClassifier` is **sensitive to the order of the columns** in the input dataset (as explained [here](https://github.com/scikit-learn/scikit-learn/issues/5394)).\n",
    "  * This makes it not suitable as results obtained via `RandomForestClassifier` might not be \"trusted\".\n",
    "  * The multilabel models being studied here are interesting, but none of them are _ground breaking_. They represent **modest improvements** by leveraging label correlations.\n",
    "  * Since the improvements are small, we must be certain that they are _not_ related to the order of the columns in the input dataset.\n",
    "  * The models based on `ClassifierChain` will **surely change the order of input columns** (at least for the columns that represent the predicted labels obtained from previous steps in the chain). Knowing that different orders will result in only modest improvements, it is important to have a base classifier that is not sensitive to the order of the columns.\n",
    "* The `K-NearestNeighbors` might be a suitable base classifier, as it is usually fast to run. We just need to make sure that:\n",
    "  * Different random states lead to different results.\n",
    "  * It will not require specific tunning.\n",
    "  * It is not sensitive to the order of the columns in the input dataset.\n",
    "\n",
    "This notebook aims at finding a suitable base classifier by testing and comparing the `SVC`, `RandomForestClassifier` and `K-NearestNeighbors`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import copy\n",
    "\n",
    "from metrics.evaluation import EvaluationPipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.646467, 0.666435, 0.685047, ..., 0.247298, 0.014025, 0.029709],\n",
       "        [0.770156, 0.767255, 0.761053, ..., 0.137833, 0.082672, 0.03632 ],\n",
       "        [0.793984, 0.772096, 0.76182 , ..., 0.051125, 0.112506, 0.083924],\n",
       "        ...,\n",
       "        [0.85639 , 1.      , 1.      , ..., 0.019464, 0.022167, 0.043738],\n",
       "        [0.805592, 0.80417 , 0.811438, ..., 0.346736, 0.231481, 0.332623],\n",
       "        [0.855064, 0.858896, 0.911177, ..., 0.262119, 0.104471, 0.34728 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.13679 , 0.354982, 0.58803 , ..., 0.124623, 0.327473, 0.204866],\n",
       "        [0.234595, 0.303399, 0.638408, ..., 0.231433, 0.347137, 0.019469],\n",
       "        [0.284239, 0.00346 , 0.726349, ..., 0.292222, 0.025036, 0.011205],\n",
       "        ...,\n",
       "        [0.34684 , 0.040355, 0.47558 , ..., 0.343549, 0.073848, 0.004937],\n",
       "        [0.153156, 0.151438, 0.561282, ..., 0.129029, 0.272418, 0.02801 ],\n",
       "        [0.195887, 0.164443, 0.496182, ..., 0.201372, 0.150776, 0.10174 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = datasets[\"scene\"][\"X_train\"]\n",
    "X_test = datasets[\"scene\"][\"X_test\"]\n",
    "\n",
    "shuffled_order = np.random.permutation(X_train.shape[1])\n",
    "shuffled_X_train = X_train[:, shuffled_order]\n",
    "shuffled_X_test = X_test[:, shuffled_order]\n",
    "\n",
    "y_train = datasets[\"scene\"][\"y_train\"]\n",
    "y_test = datasets[\"scene\"][\"y_test\"]\n",
    "\n",
    "display(X_train.todense())\n",
    "display(shuffled_X_train.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(X_train, y_train)\n",
    "    predictions = br_model.predict(X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))\n",
    "\n",
    "def run_shuffled_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(shuffled_X_train, y_train)\n",
    "    predictions = br_model.predict(shuffled_X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.1. KNN\n",
    "\n",
    "Notice: KNN has **no** `random_state`, so we will only test the ordering of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5367892976588629\n",
      "hamming loss\n",
      "0.08974358974358974\n",
      "f1 score\n",
      "0.684223851314326\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5225752508361204\n",
      "hamming loss\n",
      "0.09211259754738016\n",
      "f1 score\n",
      "0.673047351701591\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(RandomForestClassifier(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5359531772575251\n",
      "hamming loss\n",
      "0.09044035674470458\n",
      "f1 score\n",
      "0.682232461024746\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5367892976588629\n",
      "hamming loss\n",
      "0.09002229654403568\n",
      "f1 score\n",
      "0.6842674712540301\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(RandomForestClassifier(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(SVC(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(SVC(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(SVC(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(SVC(random_state=123))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
