{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import copy\n",
    "\n",
    "from metrics.evaluation import EvaluationPipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.646467, 0.666435, 0.685047, ..., 0.247298, 0.014025, 0.029709],\n",
       "        [0.770156, 0.767255, 0.761053, ..., 0.137833, 0.082672, 0.03632 ],\n",
       "        [0.793984, 0.772096, 0.76182 , ..., 0.051125, 0.112506, 0.083924],\n",
       "        ...,\n",
       "        [0.85639 , 1.      , 1.      , ..., 0.019464, 0.022167, 0.043738],\n",
       "        [0.805592, 0.80417 , 0.811438, ..., 0.346736, 0.231481, 0.332623],\n",
       "        [0.855064, 0.858896, 0.911177, ..., 0.262119, 0.104471, 0.34728 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.13679 , 0.354982, 0.58803 , ..., 0.124623, 0.327473, 0.204866],\n",
       "        [0.234595, 0.303399, 0.638408, ..., 0.231433, 0.347137, 0.019469],\n",
       "        [0.284239, 0.00346 , 0.726349, ..., 0.292222, 0.025036, 0.011205],\n",
       "        ...,\n",
       "        [0.34684 , 0.040355, 0.47558 , ..., 0.343549, 0.073848, 0.004937],\n",
       "        [0.153156, 0.151438, 0.561282, ..., 0.129029, 0.272418, 0.02801 ],\n",
       "        [0.195887, 0.164443, 0.496182, ..., 0.201372, 0.150776, 0.10174 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = datasets[\"scene\"][\"X_train\"]\n",
    "X_test = datasets[\"scene\"][\"X_test\"]\n",
    "\n",
    "shuffled_order = np.random.permutation(X_train.shape[1])\n",
    "shuffled_X_train = X_train[:, shuffled_order]\n",
    "shuffled_X_test = X_test[:, shuffled_order]\n",
    "\n",
    "y_train = datasets[\"scene\"][\"y_train\"]\n",
    "y_test = datasets[\"scene\"][\"y_test\"]\n",
    "\n",
    "display(X_train.todense())\n",
    "display(shuffled_X_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(X_train, y_train)\n",
    "    predictions = br_model.predict(X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))\n",
    "\n",
    "def run_shuffled_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(shuffled_X_train, y_train)\n",
    "    predictions = br_model.predict(shuffled_X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "# regular order\n",
    "\n",
    "knn_model = BinaryRelevance(\n",
    "    classifier=RandomForestClassifier(),\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "predictions = knn_model.predict(X_test)\n",
    "\n",
    "print(\"accuracy\")\n",
    "print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "print(\"hamming loss\")\n",
    "print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "print(\"f1 score\")\n",
    "print(metrics.f1_score(y_test, predictions, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
