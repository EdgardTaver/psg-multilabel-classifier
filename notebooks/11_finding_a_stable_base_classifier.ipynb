{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Finding a stable base classifier\n",
    "\n",
    "## 11.1. Context\n",
    "\n",
    "All multi label classifiers require a base classifier, which is a regular binary classifier.\n",
    "\n",
    "Throughout the development of this project, however, is was noted that some of these regular binary classifier present specific behaviors:\n",
    "* The `SVC`, as shown in the notebook `8` (in which I debugged why the basic stacking was no different to the regular Binary Relevance, in spite of using more features), is **apparently insensitive to additional features** (these features being the predicted labels) and also **insensitive to different random states**.\n",
    "  * This makes it not suitable as the `SVC` ends up **discarding any information regarding label correlations**.\n",
    "  * Also, since changing the random state makes no different, it is probable that the base classifier is getting to some kind of **local minimum**.\n",
    "    * Perhaps tunning the parameters of the `SVC` can solve this. However, this is not the focus of this project. I much prefer to have a very basic base classifier that works out-of-the-box.\n",
    "* The `RandomForestClassifier` is **sensitive to the order of the columns** in the input dataset (as explained [here](https://github.com/scikit-learn/scikit-learn/issues/5394)).\n",
    "  * This makes it not suitable as results obtained via `RandomForestClassifier` might not be \"trusted\".\n",
    "  * The multilabel models being studied here are interesting, but none of them are _ground breaking_. They represent **modest improvements** by leveraging label correlations.\n",
    "  * Since the improvements are small, we must be certain that they are _not_ related to the order of the columns in the input dataset.\n",
    "  * The models based on `ClassifierChain` will **surely change the order of input columns** (at least for the columns that represent the predicted labels obtained from previous steps in the chain). Knowing that different orders will result in only modest improvements, it is important to have a base classifier that is not sensitive to the order of the columns.\n",
    "* The `K-NearestNeighbors` might be a suitable base classifier, as it is usually fast to run. We just need to make sure that:\n",
    "  * Different random states lead to different results.\n",
    "  * It will not require specific tunning.\n",
    "  * It is not sensitive to the order of the columns in the input dataset.\n",
    "\n",
    "This notebook aims at finding a suitable base classifier by testing and comparing the `SVC`, `RandomForestClassifier` and `K-NearestNeighbors`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.dataset import load_dataset\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import copy\n",
    "\n",
    "from metrics.evaluation import EvaluationPipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "from lib.base_models import StackedGeneralization, DependantBinaryRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.646467, 0.666435, 0.685047, ..., 0.247298, 0.014025, 0.029709],\n",
       "        [0.770156, 0.767255, 0.761053, ..., 0.137833, 0.082672, 0.03632 ],\n",
       "        [0.793984, 0.772096, 0.76182 , ..., 0.051125, 0.112506, 0.083924],\n",
       "        ...,\n",
       "        [0.85639 , 1.      , 1.      , ..., 0.019464, 0.022167, 0.043738],\n",
       "        [0.805592, 0.80417 , 0.811438, ..., 0.346736, 0.231481, 0.332623],\n",
       "        [0.855064, 0.858896, 0.911177, ..., 0.262119, 0.104471, 0.34728 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "matrix([[1.22000e-04, 1.44418e-01, 9.40810e-02, ..., 6.85047e-01,\n",
       "         2.36605e-01, 4.77202e-01],\n",
       "        [1.60470e-02, 4.07510e-02, 2.85809e-01, ..., 7.61053e-01,\n",
       "         3.66136e-01, 4.49931e-01],\n",
       "        [7.93500e-03, 1.31860e-02, 2.91597e-01, ..., 7.61820e-01,\n",
       "         1.96590e-01, 4.50110e-01],\n",
       "        ...,\n",
       "        [1.73600e-02, 8.09100e-03, 1.03240e-01, ..., 1.00000e+00,\n",
       "         4.73331e-01, 3.59929e-01],\n",
       "        [1.66000e-04, 3.98600e-03, 4.34940e-02, ..., 8.11438e-01,\n",
       "         4.00372e-01, 3.29456e-01],\n",
       "        [9.20880e-02, 1.26706e-01, 1.35640e-02, ..., 9.11177e-01,\n",
       "         6.31460e-02, 4.25771e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = datasets[\"scene\"][\"X_train\"]\n",
    "X_test = datasets[\"scene\"][\"X_test\"]\n",
    "\n",
    "shuffled_order = np.random.permutation(X_train.shape[1])\n",
    "shuffled_X_train = X_train[:, shuffled_order]\n",
    "shuffled_X_test = X_test[:, shuffled_order]\n",
    "\n",
    "y_train = datasets[\"scene\"][\"y_train\"]\n",
    "y_test = datasets[\"scene\"][\"y_test\"]\n",
    "\n",
    "display(X_train.todense())\n",
    "display(shuffled_X_train.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regular_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(X_train, y_train)\n",
    "    predictions = br_model.predict(X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))\n",
    "\n",
    "def run_shuffled_order(model):\n",
    "    br_model = BinaryRelevance(\n",
    "        classifier=model,\n",
    "        require_dense=[False, True]\n",
    "    )\n",
    "\n",
    "    br_model.fit(shuffled_X_train, y_train)\n",
    "    predictions = br_model.predict(shuffled_X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.1. KNN\n",
    "\n",
    "Notice: KNN has **no** `random_state`, so we will only test the ordering of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.2. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5367892976588629\n",
      "hamming loss\n",
      "0.08974358974358974\n",
      "f1 score\n",
      "0.684223851314326\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5225752508361204\n",
      "hamming loss\n",
      "0.09211259754738016\n",
      "f1 score\n",
      "0.673047351701591\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(RandomForestClassifier(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5359531772575251\n",
      "hamming loss\n",
      "0.09044035674470458\n",
      "f1 score\n",
      "0.682232461024746\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5367892976588629\n",
      "hamming loss\n",
      "0.09002229654403568\n",
      "f1 score\n",
      "0.6842674712540301\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(RandomForestClassifier(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5.3. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(SVC(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_regular_order(SVC(random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(SVC(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "0.5869565217391305\n",
      "hamming loss\n",
      "0.08416945373467112\n",
      "f1 score\n",
      "0.7237789962754925\n"
     ]
    }
   ],
   "source": [
    "run_shuffled_order(SVC(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6. Notes so far\n",
    "\n",
    "* `SVC` is **not** affected by the order of the columns, but it is also **not** affected by the random state, which is bad.\n",
    "* `RandomForestClassifier` _is_ really affected by the order of the columns, which is bad.\n",
    "* `KNN` is **not** affected by the order of the columns. We cannot test the random state. So let's run one final test inspired in the notebook `8`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.7. Testing the effects of using more features on KNN\n",
    "\n",
    "We must be certain that KNN will be sensible to adding label correlation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_binary_relevance_model = BinaryRelevance(\n",
    "    classifier=KNeighborsClassifier(),\n",
    "    require_dense=[False, True]\n",
    ")\n",
    "\n",
    "basic_stacking_model = StackedGeneralization(\n",
    "    classifier=KNeighborsClassifier(),\n",
    ")\n",
    "\n",
    "dbr = DependantBinaryRelevance(\n",
    "    classifier=KNeighborsClassifier(),\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"baseline_binary_relevance_model\": baseline_binary_relevance_model,\n",
    "    \"basic_stacking_model\": basic_stacking_model,\n",
    "    \"dependant_binary_relevance\": dbr,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# running model `baseline_binary_relevance_model`\n",
      "accuracy\n",
      "0.596989966555184\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6809836443612469\n",
      "\n",
      "# running model `basic_stacking_model`\n",
      "FIT: X shape is (1211, 294)\n",
      "FIT: X_extended shape is (1211, 300)\n",
      "accuracy\n",
      "0.6078595317725752\n",
      "hamming loss\n",
      "0.10451505016722408\n",
      "f1 score\n",
      "0.6860946721513695\n",
      "\n",
      "# running model `dependant_binary_relevance`\n",
      "FIT: X shape is (1211, 294)\n",
      "FIT: X_extended shape, for label 0, is (1211, 299)\n",
      "FIT: X_extended shape, for label 1, is (1211, 299)\n",
      "FIT: X_extended shape, for label 2, is (1211, 299)\n",
      "FIT: X_extended shape, for label 3, is (1211, 299)\n",
      "FIT: X_extended shape, for label 4, is (1211, 299)\n",
      "FIT: X_extended shape, for label 5, is (1211, 299)\n",
      "accuracy\n",
      "0.6137123745819398\n",
      "hamming loss\n",
      "0.11259754738015608\n",
      "f1 score\n",
      "0.6913398386498302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"# running model `{model_name}`\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print(\"accuracy\")\n",
    "    print(metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "    print(\"hamming loss\")\n",
    "    print(metrics.hamming_loss(y_test, predictions))\n",
    "\n",
    "    print(\"f1 score\")\n",
    "    print(metrics.f1_score(y_test, predictions, average=\"macro\"))\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.8. Conclusion\n",
    "\n",
    "The `KNN` base classifier showed to also be sensible to extra features, as using label correlations changed the performance metrics (fortunately, it improved them). This is great!\n",
    "\n",
    "**It will therefore be chosen as the base classifier for the multilabel models**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
