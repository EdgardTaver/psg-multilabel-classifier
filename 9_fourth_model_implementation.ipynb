{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Fourth model implementation\n",
    "\n",
    "This notebook aims to implement the `ClassifierChain` with genetic algorithm just like described in the article `[d9e6797] LinearOrderingProblembasedClassifierChainusingGeneticAlgorithm.pdf`.\n",
    "\n",
    "## 9.1. Recapping the implementation\n",
    "\n",
    "After reading the article again, here's the main idea of the implementation:\n",
    "\n",
    "* The order os labels is chosen based on the order that showed a better \"fitness score\". Choosing a better order is handled by the genetic algorithm, and we don't have to worry about (apart from ensuring that the parameters are the same that the article used).\n",
    "* The fitness score is where we get the \"linear ordering problem\" (LOP). Here's how it works.\n",
    "  * Take a label order, for example, `[1, 4, 2, 3]`. It has `n=4` labels.\n",
    "  * Build a `n x n` matrix. Rows index are `[1, 4, 2, 3]`, and the columns are `[1, 4, 2, 3]`.\n",
    "  * Each cell of this matrix will have a value that is equal to the **conditional entropy** of the label in the row, given the label in the column. For example, the cell `[1, 4]` will have the value of the conditional entropy of the label `1`, given the label `4`.\n",
    "  * Now sum the upper triangle of this matrix. That's the **fitness score**.\n",
    "\n",
    "## 9.2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import pygad\n",
    "from typing import List\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Any, Optional\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from numpy.typing import NDArray\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from typing import cast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. Playing around with entropy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = datasets[\"scene\"][\"y_train\"]\n",
    "y.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1874483897605285,\n",
       " 0.13625103220478943,\n",
       " 0.16267547481420314,\n",
       " 0.16184971098265896,\n",
       " 0.22873658133773742,\n",
       " 0.18497109826589594]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = y.shape[1]\n",
    "rows_count = y.shape[0]\n",
    "\n",
    "probs = []\n",
    "\n",
    "for label in range(label_count):\n",
    "    instances_with_label = y[:, label].todense().sum()\n",
    "    probs.append(instances_with_label / rows_count)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45276933803928565,\n",
       " 0.3918117707258502,\n",
       " 0.4261985731270658,\n",
       " 0.42522342518043577,\n",
       " 0.4868065668618529,\n",
       " 0.45033585713511676]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropies = []\n",
    "\n",
    "for prob in probs:\n",
    "    entropy = -1 * prob * math.log(prob, 2)\n",
    "    entropies.append(entropy)\n",
    "\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.169741766696809,\n",
       "  0.13513477517031391,\n",
       "  0.15354470329775657,\n",
       "  0.15298803284199744,\n",
       "  0.19481601760076195,\n",
       "  0.1681639729896544],\n",
       " [0.13513477517031391,\n",
       "  0.10676951638276679,\n",
       "  0.12180816135339254,\n",
       "  0.12135175245007311,\n",
       "  0.15594958218271368,\n",
       "  0.13383257891815417],\n",
       " [0.15354470329775657,\n",
       "  0.12180816135339254,\n",
       "  0.1386641104971626,\n",
       "  0.1381535384751864,\n",
       "  0.17667869399503078,\n",
       "  0.1520930175359874],\n",
       " [0.15298803284199744,\n",
       "  0.12135175245007311,\n",
       "  0.1381535384751864,\n",
       "  0.13764457693701967,\n",
       "  0.17605365473154738,\n",
       "  0.15154077228645788],\n",
       " [0.19481601760076195,\n",
       "  0.15594958218271368,\n",
       "  0.17667869399503078,\n",
       "  0.17605365473154738,\n",
       "  0.22270093975348185,\n",
       "  0.19305342973037357],\n",
       " [0.1681639729896544,\n",
       "  0.13383257891815417,\n",
       "  0.1520930175359874,\n",
       "  0.15154077228645788,\n",
       "  0.19305342973037357,\n",
       "  0.16659823616559233]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_entropies = []\n",
    "\n",
    "for label in range(label_count):\n",
    "    joint_entropies.append([])\n",
    "\n",
    "    for column_position in range(label_count):\n",
    "        and_prob = probs[label] * probs[column_position]\n",
    "        joint_entropy = -1 * and_prob * math.log(and_prob, 2)\n",
    "        joint_entropies[label].append(joint_entropy)\n",
    "\n",
    "joint_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24951987913203505"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cond_entropy(x, y):\n",
    "    return joint_entropies[x][y] - entropies[y]\n",
    "\n",
    "cond_entropy(4,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I managed to implement the calculation. But the article gives the impression that, when `x` and `y` are the same, the conditional entropy should be zero. But that's not what I'm getting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2830275713424767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_entropy(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28504225434308345"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_entropy(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.28753446262990323"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_entropy(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I think that I understood what is wrong**. We are supposed to sum the probabilities, as the probability are calculated for each value that the variable may take. In the case of the labels, since they are binary, the values are either 0 or 1. We have to calculate the probabilities for 0, then 1, then sum them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.8125516102394715, 0.1874483897605285],\n",
       " [0.8637489677952106, 0.13625103220478943],\n",
       " [0.8373245251857968, 0.16267547481420314],\n",
       " [0.838150289017341, 0.16184971098265896],\n",
       " [0.7712634186622626, 0.22873658133773742],\n",
       " [0.815028901734104, 0.18497109826589594]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = y.shape[1]\n",
    "rows_count = y.shape[0]\n",
    "\n",
    "probs = []\n",
    "\n",
    "for label in range(label_count):\n",
    "    instances_with_label = y[:, label].todense().sum() # value = 1\n",
    "    instances_without_label = rows_count - instances_with_label # value = 0\n",
    "\n",
    "    probs.append([\n",
    "        instances_without_label / rows_count,  # value = 0\n",
    "        instances_with_label / rows_count,    # value = 1\n",
    "    ])\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6961030672262447,\n",
       " 0.5743357592196299,\n",
       " 0.6406718924240619,\n",
       " 0.6387163439963871,\n",
       " 0.7758023710944532,\n",
       " 0.690832038687419]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropies = []\n",
    "\n",
    "for prob in probs:\n",
    "    results = []\n",
    "    for value in [0,1]:\n",
    "        prob_for_value = prob[value]\n",
    "        summand = prob_for_value * math.log(prob_for_value, 2)\n",
    "        results.append(summand)\n",
    "    \n",
    "    entropy = -1 * sum(results)\n",
    "    entropies.append(entropy)\n",
    "\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for x=0, y=0, value_i=0, value_j=0, and_prob=0.660240119302758, math.log(and_prob, 2) = -0.5989372887101777, summand=-0.3954424269528782\n",
      "for x=0, y=0, value_i=0, value_j=1, and_prob=0.1523114909367135, math.log(and_prob, 2) = -2.714903306758502, summand=-0.4135109704014011\n",
      "for x=0, y=0, value_i=1, value_j=0, and_prob=0.1523114909367135, math.log(and_prob, 2) = -2.714903306758502, summand=-0.4135109704014011\n",
      "for x=0, y=0, value_i=1, value_j=1, and_prob=0.035136898823815, math.log(and_prob, 2) = -4.8308693248068275, summand=-0.169741766696809\n",
      "for x=0, y=1, value_i=0, value_j=0, and_prob=0.7018406146246798, math.log(and_prob, 2) = -0.5107846578024762, summand=-0.35848941817294666\n",
      "for x=0, y=1, value_i=0, value_j=1, and_prob=0.11071099561479174, math.log(and_prob, 2) = -3.175129579803602, summand=-0.3515217569860321\n",
      "for x=0, y=1, value_i=1, value_j=0, and_prob=0.16190835317053082, math.log(and_prob, 2) = -2.626750675850801, summand=-0.425292876116582\n",
      "for x=0, y=1, value_i=1, value_j=1, and_prob=0.025540036589997688, math.log(and_prob, 2) = -5.291095597851927, summand=-0.13513477517031391\n",
      "for x=0, y=2, value_i=0, value_j=0, and_prob=0.6803693912327201, math.log(and_prob, 2) = -0.5556098570460772, summand=-0.3780199402013382\n",
      "for x=0, y=2, value_i=0, value_j=1, and_prob=0.13218221900675137, math.log(and_prob, 2) = -2.9193999745930412, summand=-0.38589276680996176\n",
      "for x=0, y=2, value_i=1, value_j=0, and_prob=0.1569551339530767, math.log(and_prob, 2) = -2.671575875094402, summand=-0.41931754934125\n",
      "for x=0, y=2, value_i=1, value_j=1, and_prob=0.030493255807451786, math.log(and_prob, 2) = -5.035365992641366, summand=-0.15354470329775657\n",
      "for x=0, y=3, value_i=0, value_j=0, and_prob=0.681040366963719, math.log(and_prob, 2) = -0.5541877819768789, summand=-0.3774242504043431\n",
      "for x=0, y=3, value_i=0, value_j=1, and_prob=0.13151124327575262, math.log(and_prob, 2) = -2.9267419499342093, summand=-0.3848994725831484\n",
      "for x=0, y=3, value_i=1, value_j=0, and_prob=0.15710992205362215, math.log(and_prob, 2) = -2.670153800025204, summand=-0.4195076553931428\n",
      "for x=0, y=3, value_i=1, value_j=1, and_prob=0.030338467706906347, math.log(and_prob, 2) = -5.042707967982534, summand=-0.15298803284199744\n",
      "for x=0, y=4, value_i=0, value_j=0, and_prob=0.6266913327528211, math.log(and_prob, 2) = -0.6741730543397559, summand=-0.4224984099302217\n",
      "for x=0, y=4, value_i=0, value_j=1, and_prob=0.18586027748665038, math.log(and_prob, 2) = -2.4277096280002293, summand=-0.45121478511713536\n",
      "for x=0, y=4, value_i=1, value_j=0, and_prob=0.14457208590944146, math.log(and_prob, 2) = -2.790139072388081, summand=-0.4033762256725789\n",
      "for x=0, y=4, value_i=1, value_j=1, and_prob=0.04287630385108703, math.log(and_prob, 2) = -4.543675646048554, summand=-0.19481601760076195\n",
      "for x=0, y=5, value_i=0, value_j=0, and_prob=0.6622530464957542, math.log(and_prob, 2) = -0.59454551959302, summand=-0.39373958163087863\n",
      "for x=0, y=5, value_i=0, value_j=1, and_prob=0.15029856374371728, math.log(and_prob, 2) = -2.7340968719918135, summand=-0.4109308329965596\n",
      "for x=0, y=5, value_i=1, value_j=0, and_prob=0.1527758552383498, math.log(and_prob, 2) = -2.710511537641345, summand=-0.4141007182965711\n",
      "for x=0, y=5, value_i=1, value_j=1, and_prob=0.03467253452217868, math.log(and_prob, 2) = -4.850062890040139, summand=-0.1681639729896544\n",
      "for x=1, y=0, value_i=0, value_j=0, and_prob=0.7018406146246798, math.log(and_prob, 2) = -0.5107846578024762, summand=-0.35848941817294666\n",
      "for x=1, y=0, value_i=0, value_j=1, and_prob=0.16190835317053082, math.log(and_prob, 2) = -2.626750675850801, summand=-0.425292876116582\n",
      "for x=1, y=0, value_i=1, value_j=0, and_prob=0.11071099561479174, math.log(and_prob, 2) = -3.175129579803602, summand=-0.3515217569860321\n",
      "for x=1, y=0, value_i=1, value_j=1, and_prob=0.025540036589997688, math.log(and_prob, 2) = -5.291095597851927, summand=-0.13513477517031391\n",
      "for x=1, y=1, value_i=0, value_j=0, and_prob=0.7460622793672917, math.log(and_prob, 2) = -0.4226320268947747, summand=-0.31530981331873414\n",
      "for x=1, y=1, value_i=0, value_j=1, and_prob=0.11768668842791886, math.log(and_prob, 2) = -3.0869769488959005, summand=-0.36329609436887944\n",
      "for x=1, y=1, value_i=1, value_j=0, and_prob=0.11768668842791886, math.log(and_prob, 2) = -3.0869769488959005, summand=-0.36329609436887944\n",
      "for x=1, y=1, value_i=1, value_j=1, and_prob=0.018564343776870565, math.log(and_prob, 2) = -5.751321870897026, summand=-0.10676951638276679\n",
      "for x=1, y=2, value_i=0, value_j=0, and_prob=0.7232381943388468, math.log(and_prob, 2) = -0.46745722613837565, summand=-0.3380829201629648\n",
      "for x=1, y=2, value_i=0, value_j=1, and_prob=0.14051077345636373, math.log(and_prob, 2) = -2.83124734368534, summand=-0.3978207541075024\n",
      "for x=1, y=2, value_i=1, value_j=0, and_prob=0.11408633084695002, math.log(and_prob, 2) = -3.1318021481395015, summand=-0.35729581601983196\n",
      "for x=1, y=2, value_i=1, value_j=1, and_prob=0.022164701357839402, math.log(and_prob, 2) = -5.495592265686466, summand=-0.12180816135339254\n",
      "for x=1, y=3, value_i=0, value_j=0, and_prob=0.7239514469959857, math.log(and_prob, 2) = -0.46603515106917764, summand=-0.33738682196752395\n",
      "for x=1, y=3, value_i=0, value_j=1, and_prob=0.13979752079922483, math.log(and_prob, 2) = -2.8385893190265077, summand=-0.39682774936706566\n",
      "for x=1, y=3, value_i=1, value_j=0, and_prob=0.1141988420213553, math.log(and_prob, 2) = -3.1303800730703033, summand=-0.35748577943135423\n",
      "for x=1, y=3, value_i=1, value_j=1, and_prob=0.02205219018343413, math.log(and_prob, 2) = -5.502934241027633, summand=-0.12135175245007311\n",
      "for x=1, y=4, value_i=0, value_j=0, and_prob=0.6661779817677347, math.log(and_prob, 2) = -0.5860204234320541, summand=-0.39039390295663906\n",
      "for x=1, y=4, value_i=0, value_j=1, and_prob=0.19757098602747591, math.log(and_prob, 2) = -2.3395569970925276, summand=-0.4622285827830513\n",
      "for x=1, y=4, value_i=1, value_j=0, and_prob=0.10508543689452793, math.log(and_prob, 2) = -3.2503653454331802, summand=-0.3415660623916789\n",
      "for x=1, y=4, value_i=1, value_j=1, and_prob=0.031165595310261498, math.log(and_prob, 2) = -5.003901919093654, summand=-0.15594958218271368\n",
      "for x=1, y=5, value_i=0, value_j=0, and_prob=0.7039803725960965, math.log(and_prob, 2) = -0.5063928886853185, summand=-0.35649065445670414\n",
      "for x=1, y=5, value_i=0, value_j=1, and_prob=0.1597685951991141, math.log(and_prob, 2) = -2.6459442410841123, summand=-0.4227387943731947\n",
      "for x=1, y=5, value_i=1, value_j=0, and_prob=0.11104852913800757, math.log(and_prob, 2) = -3.170737810686444, summand=-0.3521057701589959\n",
      "for x=1, y=5, value_i=1, value_j=1, and_prob=0.02520250306678186, math.log(and_prob, 2) = -5.310289163085238, summand=-0.13383257891815417\n",
      "for x=2, y=0, value_i=0, value_j=0, and_prob=0.6803693912327201, math.log(and_prob, 2) = -0.5556098570460772, summand=-0.3780199402013382\n",
      "for x=2, y=0, value_i=0, value_j=1, and_prob=0.1569551339530767, math.log(and_prob, 2) = -2.671575875094402, summand=-0.41931754934125\n",
      "for x=2, y=0, value_i=1, value_j=0, and_prob=0.13218221900675137, math.log(and_prob, 2) = -2.9193999745930412, summand=-0.38589276680996176\n",
      "for x=2, y=0, value_i=1, value_j=1, and_prob=0.030493255807451786, math.log(and_prob, 2) = -5.035365992641366, summand=-0.15354470329775657\n",
      "for x=2, y=1, value_i=0, value_j=0, and_prob=0.7232381943388468, math.log(and_prob, 2) = -0.46745722613837565, summand=-0.3380829201629648\n",
      "for x=2, y=1, value_i=0, value_j=1, and_prob=0.11408633084695002, math.log(and_prob, 2) = -3.1318021481395015, summand=-0.35729581601983196\n",
      "for x=2, y=1, value_i=1, value_j=0, and_prob=0.14051077345636373, math.log(and_prob, 2) = -2.83124734368534, summand=-0.3978207541075024\n",
      "for x=2, y=1, value_i=1, value_j=1, and_prob=0.022164701357839402, math.log(and_prob, 2) = -5.495592265686466, summand=-0.12180816135339254\n",
      "for x=2, y=2, value_i=0, value_j=0, and_prob=0.70111236047762, math.log(and_prob, 2) = -0.5122824253819768, summand=-0.359167540490758\n",
      "for x=2, y=2, value_i=0, value_j=1, and_prob=0.13621216470817668, math.log(and_prob, 2) = -2.876072542928941, summand=-0.39175606693010145\n",
      "for x=2, y=2, value_i=1, value_j=0, and_prob=0.13621216470817668, math.log(and_prob, 2) = -2.876072542928941, summand=-0.39175606693010145\n",
      "for x=2, y=2, value_i=1, value_j=1, and_prob=0.026463310106026438, math.log(and_prob, 2) = -5.2398626604759055, summand=-0.1386641104971626\n",
      "for x=2, y=3, value_i=0, value_j=0, and_prob=0.7018037927857834, math.log(and_prob, 2) = -0.5108603503127787, summand=-0.35852373143338206\n",
      "for x=2, y=3, value_i=0, value_j=1, and_prob=0.13552073240001336, math.log(and_prob, 2) = -2.883414518270109, summand=-0.3907624473287969\n",
      "for x=2, y=3, value_i=1, value_j=0, and_prob=0.13634649623155753, math.log(and_prob, 2) = -2.874650467859743, summand=-0.39194851918308354\n",
      "for x=2, y=3, value_i=1, value_j=1, and_prob=0.026328978582645594, math.log(and_prob, 2) = -5.247204635817074, summand=-0.1381535384751864\n",
      "for x=2, y=4, value_i=0, value_j=0, and_prob=0.6457977758245534, math.log(and_prob, 2) = -0.6308456226756551, summand=-0.40739870001259354\n",
      "for x=2, y=4, value_i=0, value_j=1, and_prob=0.19152674936124336, math.log(and_prob, 2) = -2.3843821963361287, summand=-0.4566729712990807\n",
      "for x=2, y=4, value_i=1, value_j=0, and_prob=0.1254656428377091, math.log(and_prob, 2) = -2.9946357402226194, summand=-0.3757238982118098\n",
      "for x=2, y=4, value_i=1, value_j=1, and_prob=0.03720983197649403, math.log(and_prob, 2) = -4.748172313883093, summand=-0.17667869399503078\n",
      "for x=2, y=5, value_i=0, value_j=0, and_prob=0.6824436881572101, math.log(and_prob, 2) = -0.5512180879289195, summand=-0.37617530490517714\n",
      "for x=2, y=5, value_i=0, value_j=1, and_prob=0.15488083702858668, math.log(and_prob, 2) = -2.6907694403277134, summand=-0.416748623168898\n",
      "for x=2, y=5, value_i=1, value_j=0, and_prob=0.13258521357689387, math.log(and_prob, 2) = -2.915008205475884, summand=-0.38648698550141825\n",
      "for x=2, y=5, value_i=1, value_j=1, and_prob=0.03009026123730925, math.log(and_prob, 2) = -5.054559557874677, summand=-0.1520930175359874\n",
      "for x=3, y=0, value_i=0, value_j=0, and_prob=0.681040366963719, math.log(and_prob, 2) = -0.5541877819768789, summand=-0.3774242504043431\n",
      "for x=3, y=0, value_i=0, value_j=1, and_prob=0.15710992205362215, math.log(and_prob, 2) = -2.670153800025204, summand=-0.4195076553931428\n",
      "for x=3, y=0, value_i=1, value_j=0, and_prob=0.13151124327575262, math.log(and_prob, 2) = -2.9267419499342093, summand=-0.3848994725831484\n",
      "for x=3, y=0, value_i=1, value_j=1, and_prob=0.030338467706906347, math.log(and_prob, 2) = -5.042707967982534, summand=-0.15298803284199744\n",
      "for x=3, y=1, value_i=0, value_j=0, and_prob=0.7239514469959857, math.log(and_prob, 2) = -0.46603515106917764, summand=-0.33738682196752395\n",
      "for x=3, y=1, value_i=0, value_j=1, and_prob=0.1141988420213553, math.log(and_prob, 2) = -3.1303800730703033, summand=-0.35748577943135423\n",
      "for x=3, y=1, value_i=1, value_j=0, and_prob=0.13979752079922483, math.log(and_prob, 2) = -2.8385893190265077, summand=-0.39682774936706566\n",
      "for x=3, y=1, value_i=1, value_j=1, and_prob=0.02205219018343413, math.log(and_prob, 2) = -5.502934241027633, summand=-0.12135175245007311\n",
      "for x=3, y=2, value_i=0, value_j=0, and_prob=0.7018037927857834, math.log(and_prob, 2) = -0.5108603503127787, summand=-0.35852373143338206\n",
      "for x=3, y=2, value_i=0, value_j=1, and_prob=0.13634649623155753, math.log(and_prob, 2) = -2.874650467859743, summand=-0.39194851918308354\n",
      "for x=3, y=2, value_i=1, value_j=0, and_prob=0.13552073240001336, math.log(and_prob, 2) = -2.883414518270109, summand=-0.3907624473287969\n",
      "for x=3, y=2, value_i=1, value_j=1, and_prob=0.026328978582645594, math.log(and_prob, 2) = -5.247204635817074, summand=-0.1381535384751864\n",
      "for x=3, y=3, value_i=0, value_j=0, and_prob=0.7024959069798523, math.log(and_prob, 2) = -0.5094382752435803, summand=-0.3578783032174906\n",
      "for x=3, y=3, value_i=0, value_j=1, and_prob=0.13565438203748872, math.log(and_prob, 2) = -2.8819924432009105, summand=-0.39095490391913185\n",
      "for x=3, y=3, value_i=1, value_j=0, and_prob=0.13565438203748872, math.log(and_prob, 2) = -2.8819924432009105, summand=-0.39095490391913185\n",
      "for x=3, y=3, value_i=1, value_j=1, and_prob=0.026195328945170238, math.log(and_prob, 2) = -5.254546611158242, summand=-0.13764457693701967\n",
      "for x=3, y=4, value_i=0, value_j=0, and_prob=0.6464346572602778, math.log(and_prob, 2) = -0.6294235476064571, summand=-0.4068811952685283\n",
      "for x=3, y=4, value_i=0, value_j=1, and_prob=0.19171563175706313, math.log(and_prob, 2) = -2.382960121266931, summand=-0.4568507051005774\n",
      "for x=3, y=4, value_i=1, value_j=0, and_prob=0.12482876140198469, math.log(and_prob, 2) = -3.001977715563788, summand=-0.37473315999018714\n",
      "for x=3, y=4, value_i=1, value_j=1, and_prob=0.03702094958067426, math.log(and_prob, 2) = -4.755514289224261, summand=-0.17605365473154738\n",
      "for x=3, y=5, value_i=0, value_j=0, and_prob=0.6831167095459253, math.log(and_prob, 2) = -0.5497960128597214, summand=-0.3755748432262021\n",
      "for x=3, y=5, value_i=0, value_j=1, and_prob=0.15503357947141566, math.log(and_prob, 2) = -2.689347365258515, summand=-0.4169391484780483\n",
      "for x=3, y=5, value_i=1, value_j=0, and_prob=0.13191219218817868, math.log(and_prob, 2) = -2.9223501808170522, summand=-0.38549361869309773\n",
      "for x=3, y=5, value_i=1, value_j=1, and_prob=0.02993751879448027, math.log(and_prob, 2) = -5.0619015332158455, summand=-0.15154077228645788\n",
      "for x=4, y=0, value_i=0, value_j=0, and_prob=0.6266913327528211, math.log(and_prob, 2) = -0.6741730543397559, summand=-0.4224984099302217\n",
      "for x=4, y=0, value_i=0, value_j=1, and_prob=0.14457208590944146, math.log(and_prob, 2) = -2.790139072388081, summand=-0.4033762256725789\n",
      "for x=4, y=0, value_i=1, value_j=0, and_prob=0.18586027748665038, math.log(and_prob, 2) = -2.4277096280002293, summand=-0.45121478511713536\n",
      "for x=4, y=0, value_i=1, value_j=1, and_prob=0.04287630385108703, math.log(and_prob, 2) = -4.543675646048554, summand=-0.19481601760076195\n",
      "for x=4, y=1, value_i=0, value_j=0, and_prob=0.6661779817677347, math.log(and_prob, 2) = -0.5860204234320541, summand=-0.39039390295663906\n",
      "for x=4, y=1, value_i=0, value_j=1, and_prob=0.10508543689452793, math.log(and_prob, 2) = -3.2503653454331802, summand=-0.3415660623916789\n",
      "for x=4, y=1, value_i=1, value_j=0, and_prob=0.19757098602747591, math.log(and_prob, 2) = -2.3395569970925276, summand=-0.4622285827830513\n",
      "for x=4, y=1, value_i=1, value_j=1, and_prob=0.031165595310261498, math.log(and_prob, 2) = -5.003901919093654, summand=-0.15594958218271368\n",
      "for x=4, y=2, value_i=0, value_j=0, and_prob=0.6457977758245534, math.log(and_prob, 2) = -0.6308456226756551, summand=-0.40739870001259354\n",
      "for x=4, y=2, value_i=0, value_j=1, and_prob=0.1254656428377091, math.log(and_prob, 2) = -2.9946357402226194, summand=-0.3757238982118098\n",
      "for x=4, y=2, value_i=1, value_j=0, and_prob=0.19152674936124336, math.log(and_prob, 2) = -2.3843821963361287, summand=-0.4566729712990807\n",
      "for x=4, y=2, value_i=1, value_j=1, and_prob=0.03720983197649403, math.log(and_prob, 2) = -4.748172313883093, summand=-0.17667869399503078\n",
      "for x=4, y=3, value_i=0, value_j=0, and_prob=0.6464346572602778, math.log(and_prob, 2) = -0.6294235476064571, summand=-0.4068811952685283\n",
      "for x=4, y=3, value_i=0, value_j=1, and_prob=0.12482876140198469, math.log(and_prob, 2) = -3.001977715563788, summand=-0.37473315999018714\n",
      "for x=4, y=3, value_i=1, value_j=0, and_prob=0.19171563175706313, math.log(and_prob, 2) = -2.382960121266931, summand=-0.4568507051005774\n",
      "for x=4, y=3, value_i=1, value_j=1, and_prob=0.03702094958067426, math.log(and_prob, 2) = -4.755514289224261, summand=-0.17605365473154738\n",
      "for x=4, y=4, value_i=0, value_j=0, and_prob=0.5948472609666005, math.log(and_prob, 2) = -0.7494088199693338, summand=-0.4457837839029704\n",
      "for x=4, y=4, value_i=0, value_j=1, and_prob=0.17641615769566205, math.log(and_prob, 2) = -2.5029453936298074, summand=-0.441560009266227\n",
      "for x=4, y=4, value_i=1, value_j=0, and_prob=0.17641615769566205, math.log(and_prob, 2) = -2.5029453936298074, summand=-0.441560009266227\n",
      "for x=4, y=4, value_i=1, value_j=1, and_prob=0.05232042364207536, math.log(and_prob, 2) = -4.256481967290281, summand=-0.22270093975348185\n",
      "for x=4, y=5, value_i=0, value_j=0, and_prob=0.6286019770599943, math.log(and_prob, 2) = -0.669781285222598, summand=-0.4210258400887091\n",
      "for x=4, y=5, value_i=0, value_j=1, and_prob=0.1426614416022682, math.log(and_prob, 2) = -2.8093326376213916, summand=-0.4007834440233703\n",
      "for x=4, y=5, value_i=1, value_j=0, and_prob=0.18642692467410968, math.log(and_prob, 2) = -2.4233178588830717, summand=-0.4517716959394192\n",
      "for x=4, y=5, value_i=1, value_j=1, and_prob=0.04230965666362773, math.log(and_prob, 2) = -4.562869211281865, summand=-0.19305342973037357\n",
      "for x=5, y=0, value_i=0, value_j=0, and_prob=0.6622530464957542, math.log(and_prob, 2) = -0.59454551959302, summand=-0.39373958163087863\n",
      "for x=5, y=0, value_i=0, value_j=1, and_prob=0.1527758552383498, math.log(and_prob, 2) = -2.710511537641345, summand=-0.4141007182965711\n",
      "for x=5, y=0, value_i=1, value_j=0, and_prob=0.15029856374371728, math.log(and_prob, 2) = -2.7340968719918135, summand=-0.4109308329965596\n",
      "for x=5, y=0, value_i=1, value_j=1, and_prob=0.03467253452217868, math.log(and_prob, 2) = -4.850062890040139, summand=-0.1681639729896544\n",
      "for x=5, y=1, value_i=0, value_j=0, and_prob=0.7039803725960965, math.log(and_prob, 2) = -0.5063928886853185, summand=-0.35649065445670414\n",
      "for x=5, y=1, value_i=0, value_j=1, and_prob=0.11104852913800757, math.log(and_prob, 2) = -3.170737810686444, summand=-0.3521057701589959\n",
      "for x=5, y=1, value_i=1, value_j=0, and_prob=0.1597685951991141, math.log(and_prob, 2) = -2.6459442410841123, summand=-0.4227387943731947\n",
      "for x=5, y=1, value_i=1, value_j=1, and_prob=0.02520250306678186, math.log(and_prob, 2) = -5.310289163085238, summand=-0.13383257891815417\n",
      "for x=5, y=2, value_i=0, value_j=0, and_prob=0.6824436881572101, math.log(and_prob, 2) = -0.5512180879289195, summand=-0.37617530490517714\n",
      "for x=5, y=2, value_i=0, value_j=1, and_prob=0.13258521357689387, math.log(and_prob, 2) = -2.915008205475884, summand=-0.38648698550141825\n",
      "for x=5, y=2, value_i=1, value_j=0, and_prob=0.15488083702858668, math.log(and_prob, 2) = -2.6907694403277134, summand=-0.416748623168898\n",
      "for x=5, y=2, value_i=1, value_j=1, and_prob=0.03009026123730925, math.log(and_prob, 2) = -5.054559557874677, summand=-0.1520930175359874\n",
      "for x=5, y=3, value_i=0, value_j=0, and_prob=0.6831167095459253, math.log(and_prob, 2) = -0.5497960128597214, summand=-0.3755748432262021\n",
      "for x=5, y=3, value_i=0, value_j=1, and_prob=0.13191219218817868, math.log(and_prob, 2) = -2.9223501808170522, summand=-0.38549361869309773\n",
      "for x=5, y=3, value_i=1, value_j=0, and_prob=0.15503357947141566, math.log(and_prob, 2) = -2.689347365258515, summand=-0.4169391484780483\n",
      "for x=5, y=3, value_i=1, value_j=1, and_prob=0.02993751879448027, math.log(and_prob, 2) = -5.0619015332158455, summand=-0.15154077228645788\n",
      "for x=5, y=4, value_i=0, value_j=0, and_prob=0.6286019770599943, math.log(and_prob, 2) = -0.669781285222598, summand=-0.4210258400887091\n",
      "for x=5, y=4, value_i=0, value_j=1, and_prob=0.18642692467410968, math.log(and_prob, 2) = -2.4233178588830717, summand=-0.4517716959394192\n",
      "for x=5, y=4, value_i=1, value_j=0, and_prob=0.1426614416022682, math.log(and_prob, 2) = -2.8093326376213916, summand=-0.4007834440233703\n",
      "for x=5, y=4, value_i=1, value_j=1, and_prob=0.04230965666362773, math.log(and_prob, 2) = -4.562869211281865, summand=-0.19305342973037357\n",
      "for x=5, y=5, value_i=0, value_j=0, and_prob=0.6642721106618998, math.log(and_prob, 2) = -0.5901537504758622, summand=-0.3920226774436371\n",
      "for x=5, y=5, value_i=0, value_j=1, and_prob=0.15075679107220422, math.log(and_prob, 2) = -2.729705102874656, summand=-0.41152158188280424\n",
      "for x=5, y=5, value_i=1, value_j=0, and_prob=0.15075679107220422, math.log(and_prob, 2) = -2.729705102874656, summand=-0.41152158188280424\n",
      "for x=5, y=5, value_i=1, value_j=1, and_prob=0.034214307193691736, math.log(and_prob, 2) = -4.86925645527345, summand=-0.16659823616559233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.3922061344524894,\n",
       "  1.2704388264458748,\n",
       "  1.3367749596503065,\n",
       "  1.3348194112226317,\n",
       "  1.471905438320698,\n",
       "  1.3869351059136636],\n",
       " [1.2704388264458748,\n",
       "  1.14867151843926,\n",
       "  1.2150076516436918,\n",
       "  1.2130521032160169,\n",
       "  1.350138130314083,\n",
       "  1.265167797907049],\n",
       " [1.3367749596503065,\n",
       "  1.2150076516436918,\n",
       "  1.2813437848481235,\n",
       "  1.279388236420449,\n",
       "  1.416474263518515,\n",
       "  1.3315039311114807],\n",
       " [1.3348194112226317,\n",
       "  1.2130521032160169,\n",
       "  1.279388236420449,\n",
       "  1.2774326879927738,\n",
       "  1.4145187150908403,\n",
       "  1.3295483826838062],\n",
       " [1.471905438320698,\n",
       "  1.350138130314083,\n",
       "  1.4164742635185146,\n",
       "  1.4145187150908403,\n",
       "  1.5516047421889063,\n",
       "  1.4666344097818722],\n",
       " [1.3869351059136636,\n",
       "  1.265167797907049,\n",
       "  1.3315039311114807,\n",
       "  1.329548382683806,\n",
       "  1.4666344097818722,\n",
       "  1.3816640773748379]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_entropies = []\n",
    "\n",
    "# for prob in probs:\n",
    "#     for value_i in [0,1]:\n",
    "#         for value_j in [0,1]:\n",
    "#             and_prob = prob[value_i] * prob[value_j]\n",
    "\n",
    "#             joint_entropy = -1 * and_prob * math.log(and_prob, 2)\n",
    "#             joint_entropies.append(joint_entropy)\n",
    "\n",
    "for x in range(label_count):\n",
    "    joint_entropies.append([])\n",
    "\n",
    "    for y in range(label_count):\n",
    "        results = []\n",
    "        for value_i in [0,1]:\n",
    "            for value_j in [0,1]:\n",
    "                and_prob = probs[x][value_i] * probs[y][value_j]\n",
    "                summand = and_prob * math.log(and_prob, 2)\n",
    "                results.append(summand)\n",
    "                print(f\"for x={x}, y={y}, value_i={value_i}, value_j={value_j}, and_prob={and_prob}, math.log(and_prob, 2) = {math.log(and_prob, 2)}, summand={summand}\")\n",
    "\n",
    "        joint_entropy = -1 * sum(results)\n",
    "        joint_entropies[x].append(joint_entropy)\n",
    "\n",
    "joint_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3922061344524894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_joint_entropy(x, y, probs):\n",
    "    results = []\n",
    "    for value_i in [0,1]:\n",
    "        for value_j in [0,1]:\n",
    "            and_prob = probs[x][value_i] * probs[y][value_j]\n",
    "            # summand = and_prob * np.log2(and_prob) \n",
    "\n",
    "            if and_prob > 0:  # Avoid taking the log of 0\n",
    "                summand = and_prob * np.log2(and_prob)\n",
    "                results.append(summand)\n",
    "    \n",
    "    return -1 * sum(results)\n",
    "\n",
    "get_joint_entropy(0, 0, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_entropy(x, y):\n",
    "    return joint_entropies[x][y] - entropies[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14867151843926\n",
      "0.5743357592196299\n",
      "0.5743357592196299\n",
      "1.1486715184392597\n"
     ]
    }
   ],
   "source": [
    "print(joint_entropies[1][1])\n",
    "print(entropies[1])\n",
    "print(entropies[1])\n",
    "print(entropies[1]+ entropies[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6961030672262447\n",
      "0.6961030672262449\n",
      "0.6961030672262446\n",
      "0.6961030672262446\n",
      "0.6961030672262448\n",
      "0.6961030672262446\n",
      "0.5743357592196301\n",
      "0.5743357592196301\n",
      "0.57433575921963\n",
      "0.5743357592196298\n",
      "0.5743357592196298\n",
      "0.57433575921963\n",
      "0.6406718924240618\n",
      "0.640671892424062\n",
      "0.6406718924240616\n",
      "0.6406718924240619\n",
      "0.6406718924240619\n",
      "0.6406718924240616\n",
      "0.638716343996387\n",
      "0.638716343996387\n",
      "0.6387163439963871\n",
      "0.6387163439963867\n",
      "0.6387163439963871\n",
      "0.6387163439963871\n",
      "0.7758023710944533\n",
      "0.775802371094453\n",
      "0.7758023710944527\n",
      "0.7758023710944532\n",
      "0.7758023710944532\n",
      "0.7758023710944532\n",
      "0.6908320386874189\n",
      "0.6908320386874192\n",
      "0.6908320386874188\n",
      "0.6908320386874188\n",
      "0.690832038687419\n",
      "0.6908320386874188\n"
     ]
    }
   ],
   "source": [
    "for label in range(label_count):\n",
    "    for column_position in range(label_count):\n",
    "        print(cond_entropy(label,column_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5743357592196298\n",
      "0.638716343996387\n"
     ]
    }
   ],
   "source": [
    "print(cond_entropy(1,3))\n",
    "print(cond_entropy(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honestly, I think that I got it right... I was expecting conditional_entropy to be zero, as the article states that:\n",
    "\n",
    "> If condEntropy(X /Y ) = 0, X has no uncertainty in the Y â€™s presence, i.e., X can be determined entirely by Y.\n",
    "\n",
    "So if X and Y are the same variable, obviously knowing X determines Y. But the calculations provided in the article, which I could verify [here](https://www.ece.tufts.edu/ee/194NIT/lect01.pdf), [here](https://en.wikipedia.org/wiki/Joint_entropy) and even [here](https://gist.github.com/kudkudak/dabbed1af234c8e3868e) and also [here](https://www.cs.cmu.edu/~venkatg/teaching/ITCS-spr2013/notes/lect-jan17.pdf), will obviously lead to the joint entropy of X,X always being the sum of the entropy of X and the entropy of X. And since conditional entropy is the joint entropy minus the entropy of Y, it will always be the entropy of X.\n",
    "\n",
    "The reason for that is that the formula for the joint entropy takes two sums, one for X and one for Y. So when X and Y are the same, we have to sum the entropy of X twice. Therefore, the joint entropy of X,X will always be the entropy of X multiplied by 2. If you subtract the entropy of Y, which is zero, you will always get the entropy of X.\n",
    "\n",
    "Other implementation in Python seen [here](https://datascience.stackexchange.com/questions/58565/conditional-entropy-calculation-in-python-hyx).\n",
    "\n",
    "_So my implementation is most likely correct_. The only weird thing is that the final conditional entropy values are very similar across the same row (same X, or same Y). I don't know if that's normal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4. Stablish code for entropy calculation\n",
    "\n",
    "Now that we are comfortable with the entropy calculation, let's make a more \"stable\" code for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by Copilot:\n",
    "\n",
    "class Entropy:\n",
    "    def __init__(self, probs):\n",
    "        self.probs = probs\n",
    "        self.label_count = len(probs)\n",
    "        self.entropies = self._get_entropies()\n",
    "        self.joint_entropies = self._get_joint_entropies()\n",
    "    \n",
    "    def _get_entropies(self):\n",
    "        entropies = []\n",
    "\n",
    "        for prob in self.probs:\n",
    "            results = []\n",
    "            for value in [0,1]:\n",
    "                prob_for_value = prob[value]\n",
    "                summand = prob_for_value * math.log(prob_for_value, 2)\n",
    "                results.append(summand)\n",
    "            \n",
    "            entropy = -1 * sum(results)\n",
    "            entropies.append(entropy)\n",
    "\n",
    "        return entropies\n",
    "\n",
    "    def _get_joint_entropies(self):\n",
    "        joint_entropies = []\n",
    "\n",
    "        for x in range(self.label_count):\n",
    "            joint_entropies.append([])\n",
    "\n",
    "            for y in range(self.label_count):\n",
    "                results = []\n",
    "                for value_i in [0,1]:\n",
    "                    for value_j in [0,1]:\n",
    "                        and_prob = self.probs[x][value_i] * self.probs[y][value_j]\n",
    "                        summand = and_prob * math.log(and_prob, 2)\n",
    "                        results.append(summand)\n",
    "                        # print(f\"for x={x}, y={y}, value_i={value_i}, value_j={value_j}, and_prob={and_prob}, math.log(and_prob, 2) = {math.log(and_prob, 2)}, summand={summand}\")\n",
    "\n",
    "                joint_entropy = -1 * sum(results)\n",
    "                joint_entropies[x].append(joint_entropy)\n",
    "\n",
    "        return joint_entropies\n",
    "\n",
    "    def get_cond_entropy(self, x, y):\n",
    "        return self.joint_entropies[x][y] - self.entropies[y]\n",
    "\n",
    "    def get_cond_entropy_matrix(self):\n",
    "        matrix = []\n",
    "\n",
    "        for i in range(self.label_count):\n",
    "            matrix.append([])\n",
    "            for j in range(self.label_count):\n",
    "                matrix[i].append(self.get_cond_entropy(i,j))\n",
    "        \n",
    "        return matrix\n",
    "\n",
    "    def get_cond_entropy_matrix(self):\n",
    "        matrix = []\n",
    "\n",
    "        for i in range(self.label_count):\n",
    "            matrix.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: 0.8125516102394715, 1: 0.1874483897605285},\n",
       " 1: {0: 0.8637489677952106, 1: 0.13625103220478943},\n",
       " 2: {0: 0.8373245251857968, 1: 0.16267547481420314},\n",
       " 3: {0: 0.838150289017341, 1: 0.16184971098265896},\n",
       " 4: {0: 0.7712634186622626, 1: 0.22873658133773742},\n",
       " 5: {0: 0.815028901734104, 1: 0.18497109826589594}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Probabilities = Dict[int, Dict[int, float]]\n",
    "\n",
    "def calculate_probabilities(y: NDArray[np.int64]) -> Probabilities:\n",
    "    dense_y = y.todense()\n",
    "\n",
    "    label_count = dense_y.shape[1]\n",
    "    rows_count = dense_y.shape[0]\n",
    "\n",
    "    probs = {}\n",
    "\n",
    "    for label in range(label_count):\n",
    "        probs[label] = {}\n",
    "        y_label_specific = np.asarray(dense_y[:, label]).reshape(-1)\n",
    "        # convert_matrix_to_vector\n",
    "\n",
    "        possible_values = np.unique(y_label_specific)\n",
    "\n",
    "        for value in possible_values:\n",
    "            instances_with_label = np.count_nonzero(y_label_specific == value)\n",
    "            probs[label][value] = instances_with_label / rows_count\n",
    "    \n",
    "    return probs\n",
    "\n",
    "y = datasets[\"scene\"][\"y_train\"]\n",
    "probs = calculate_probabilities(y)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6961030672262447,\n",
       " 1: 0.5743357592196299,\n",
       " 2: 0.6406718924240619,\n",
       " 3: 0.6387163439963871,\n",
       " 4: 0.7758023710944532,\n",
       " 5: 0.690832038687419}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Entropies = Dict[int, float]\n",
    "\n",
    "def calculate_entropies(probabilities: Probabilities) -> Entropies:\n",
    "    entropies = {}\n",
    "\n",
    "    for label, calculated_probabilities in probabilities.items():\n",
    "        results = []\n",
    "        for _, prob in calculated_probabilities.items():\n",
    "            summand = prob * math.log(prob, 2)\n",
    "            results.append(summand)\n",
    "        \n",
    "        entropy = -1 * sum(results)\n",
    "        entropies[label] = entropy\n",
    "\n",
    "    return entropies\n",
    "\n",
    "entropies = calculate_entropies(probs)\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3922061344524894"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_joint_probability(probabilities: Probabilities, label_x: int, label_y: int):\n",
    "    results = []\n",
    "    \n",
    "    for _, prob_i in probabilities[label_x].items():\n",
    "        for _, prob_j in probabilities[label_y].items():\n",
    "            and_prob = prob_i * prob_j\n",
    "\n",
    "            if and_prob > 0:  # avoid taking the log of 0\n",
    "                summand = and_prob * np.log2(and_prob)\n",
    "                results.append(summand)\n",
    "    \n",
    "    joint_probability = -1 * sum(results)\n",
    "    return joint_probability\n",
    "\n",
    "calculate_joint_probability(probs, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.638716343996387"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_conditional_entropy(probabilities: Probabilities, entropies: Entropies, label_x: int, label_y: int):\n",
    "    joint_entropy = calculate_joint_probability(probabilities, label_x, label_y)\n",
    "    entropy = entropies[label_y]\n",
    "    return joint_entropy - entropy\n",
    "\n",
    "calculate_conditional_entropy(probs, entropies, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.5. Actually solving the LOP\n",
    "\n",
    "Now that we can easily calculate the entropies, let's focus on solving the linear ordering problem (LOP) that the article suggests.\n",
    "\n",
    "Recapping again, the article proposes that:\n",
    "* We get an `n x n` matrix, where `n` is the number of labels.\n",
    "* The rows and columns are the labels.\n",
    "* Each cell in the matrix is the conditional entropy of the label in the row, given the label in the column.\n",
    "* We sum the upper triangle of the matrix. That's the fitness score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.775802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.574336</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.640672</td>\n",
       "      <td>0.696103</td>\n",
       "      <td>0.690832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         3         2         0         5         4\n",
       "1  0.000000  0.638716  0.640672  0.696103  0.690832  0.775802\n",
       "3  0.574336  0.000000  0.640672  0.696103  0.690832  0.775802\n",
       "2  0.574336  0.638716  0.000000  0.696103  0.690832  0.775802\n",
       "0  0.574336  0.638716  0.640672  0.000000  0.690832  0.775802\n",
       "5  0.574336  0.638716  0.640672  0.696103  0.000000  0.775802\n",
       "4  0.574336  0.638716  0.640672  0.696103  0.690832  0.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = y.shape[1]\n",
    "\n",
    "label_order = [1, 3, 2, 0, 5, 4]\n",
    "# trying a random order to see if it works\n",
    "\n",
    "matrix = {}\n",
    "\n",
    "for row_i in label_order:\n",
    "    matrix[row_i] = {}\n",
    "    for row_j in label_order:\n",
    "        if row_i == row_j:\n",
    "            matrix[row_i][row_j] = 0\n",
    "            # this is to match the table described in the paper\n",
    "            # but in reality we _have_ a >0 conditional entropy for a label with itself\n",
    "            continue\n",
    "\n",
    "        cond_entropy = calculate_conditional_entropy(probs, entropies, row_i, row_j)\n",
    "        matrix[row_i][row_j] = cond_entropy\n",
    "    \n",
    "t = pd.DataFrame(matrix)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: 0,\n",
       "  3: 0.5743357592196298,\n",
       "  2: 0.5743357592196298,\n",
       "  0: 0.5743357592196296,\n",
       "  5: 0.5743357592196298,\n",
       "  4: 0.5743357592196298},\n",
       " 3: {1: 0.638716343996387,\n",
       "  3: 0,\n",
       "  2: 0.6387163439963869,\n",
       "  0: 0.638716343996387,\n",
       "  5: 0.6387163439963869,\n",
       "  4: 0.6387163439963871},\n",
       " 2: {1: 0.6406718924240618,\n",
       "  3: 0.6406718924240616,\n",
       "  2: 0,\n",
       "  0: 0.6406718924240618,\n",
       "  5: 0.6406718924240614,\n",
       "  4: 0.6406718924240619},\n",
       " 0: {1: 0.6961030672262445,\n",
       "  3: 0.6961030672262446,\n",
       "  2: 0.6961030672262446,\n",
       "  0: 0,\n",
       "  5: 0.6961030672262446,\n",
       "  4: 0.6961030672262448},\n",
       " 5: {1: 0.6908320386874189,\n",
       "  3: 0.6908320386874188,\n",
       "  2: 0.6908320386874186,\n",
       "  0: 0.6908320386874189,\n",
       "  5: 0,\n",
       "  4: 0.690832038687419},\n",
       " 4: {1: 0.775802371094453,\n",
       "  3: 0.7758023710944532,\n",
       "  2: 0.7758023710944527,\n",
       "  0: 0.7758023710944533,\n",
       "  5: 0.7758023710944532,\n",
       "  4: 0}}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.650709340745188"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size_n = t.shape[0]\n",
    "\n",
    "upper_triangule_sum = 0\n",
    "for row_position in range(matrix_size_n):\n",
    "    for column_position in range(matrix_size_n):\n",
    "        if column_position > row_position:\n",
    "            upper_triangule_sum += t.iloc[row_position,column_position]\n",
    "\n",
    "upper_triangule_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.650706999999999"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.638716+0.640672+0.696103+0.690832+0.775802) + \\\n",
    "    (0.640672+0.696103+0.690832+0.775802) + \\\n",
    "        (0.696103+0.690832+0.775802) + (0.690832+0.775802) + 0.775802"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly as before, let's now build a _final code_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: 0,\n",
       "  3: 0.5743357592196298,\n",
       "  2: 0.5743357592196298,\n",
       "  0: 0.5743357592196296,\n",
       "  5: 0.5743357592196298,\n",
       "  4: 0.5743357592196298},\n",
       " 3: {1: 0.638716343996387,\n",
       "  3: 0,\n",
       "  2: 0.6387163439963869,\n",
       "  0: 0.638716343996387,\n",
       "  5: 0.6387163439963869,\n",
       "  4: 0.6387163439963871},\n",
       " 2: {1: 0.6406718924240618,\n",
       "  3: 0.6406718924240616,\n",
       "  2: 0,\n",
       "  0: 0.6406718924240618,\n",
       "  5: 0.6406718924240614,\n",
       "  4: 0.6406718924240619},\n",
       " 0: {1: 0.6961030672262445,\n",
       "  3: 0.6961030672262446,\n",
       "  2: 0.6961030672262446,\n",
       "  0: 0,\n",
       "  5: 0.6961030672262446,\n",
       "  4: 0.6961030672262448},\n",
       " 5: {1: 0.6908320386874189,\n",
       "  3: 0.6908320386874188,\n",
       "  2: 0.6908320386874186,\n",
       "  0: 0.6908320386874189,\n",
       "  5: 0,\n",
       "  4: 0.690832038687419},\n",
       " 4: {1: 0.775802371094453,\n",
       "  3: 0.7758023710944532,\n",
       "  2: 0.7758023710944527,\n",
       "  0: 0.7758023710944533,\n",
       "  5: 0.7758023710944532,\n",
       "  4: 0}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOPMatrix = Dict[int, Dict[int, float]]\n",
    "\n",
    "def build_lop_matrix(\n",
    "    label_order: List[int],\n",
    "    probabilities: Probabilities,\n",
    "    entropies: Entropies\n",
    ") -> LOPMatrix:\n",
    "    matrix = {}\n",
    "\n",
    "    for row_i in label_order:\n",
    "        matrix[row_i] = {}\n",
    "        for row_j in label_order:\n",
    "            if row_i == row_j:\n",
    "                matrix[row_i][row_j] = 0\n",
    "                # this is to match the table described in the paper\n",
    "                # but in reality we _have_ a >0 conditional entropy for a label with itself\n",
    "                continue\n",
    "\n",
    "            cond_entropy = calculate_conditional_entropy(probabilities, entropies, row_i, row_j)\n",
    "            matrix[row_i][row_j] = cond_entropy\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "label_order = [1, 3, 2, 0, 5, 4]\n",
    "# trying a random order to see if it works\n",
    "lop_matrix = build_lop_matrix(label_order, probs, entropies)\n",
    "lop_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.650709340745188"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_lop(lop_matrix: LOPMatrix) -> float:\n",
    "    matrix_size_n = len(lop_matrix)\n",
    "    lop_df = pd.DataFrame(lop_matrix)\n",
    "\n",
    "    upper_triangle_sum = 0\n",
    "    for row_position in range(matrix_size_n):\n",
    "        for column_position in range(matrix_size_n):\n",
    "            if column_position > row_position:\n",
    "                conditional_probability = lop_df.iloc[row_position, column_position]\n",
    "                upper_triangle_sum += cast(float, conditional_probability)\n",
    "                # the conversion to a dataframe is not necessary\n",
    "                # but makes it easier to find the element we want\n",
    "                # by their order in the rows or columns\n",
    "                # instead of the actual column or row index\n",
    "    \n",
    "    return upper_triangle_sum\n",
    "\n",
    "calculate_lop(lop_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5.1 Why summing the upper triangle?\n",
    "\n",
    "The article proposes that the we sum the upper triangle of the LOP matrix, and this sum is the value of the fitness score.\n",
    "\n",
    "My interpretation is that, since the article states that labels with more uncertainty (higher entropy) should be placed towards the end of the chain, then the upper triangle, as it considers all elements above the diagonal, will give a \"higher weight\" to the labels towards the end of the chain.\n",
    "\n",
    "If the labels towards the end of the chain really have higher entropies, then the final column will carry the highest values seen. Summing all of that, we will end up with a higher fitness score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.6. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.967467469102132"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_solution(y: NDArray[np.int64], label_order: List[int]) -> float:\n",
    "    probs = calculate_probabilities(y)\n",
    "    entropies = calculate_entropies(probs)\n",
    "    lop_matrix = build_lop_matrix(label_order, probs, entropies)\n",
    "    return calculate_lop(lop_matrix)\n",
    "\n",
    "y = datasets[\"scene\"][\"y_train\"]\n",
    "label_order = [4, 1, 3, 5, 2, 0]\n",
    "test_solution(y, label_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 5, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10.351147933185574"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_count = y.shape[1]\n",
    "label_space = np.arange(label_count)\n",
    "\n",
    "def fitness_func(ga_instance: Any, solution: Any, solution_idx: Any) -> float:\n",
    "    probs = calculate_probabilities(y)\n",
    "    entropies = calculate_entropies(probs)\n",
    "    lop_matrix = build_lop_matrix(solution, probs, entropies)\n",
    "    return calculate_lop(lop_matrix)\n",
    "\n",
    "ga_model = pygad.GA( #type:ignore\n",
    "    gene_type=int,\n",
    "    gene_space=label_space,\n",
    "    save_best_solutions=False,\n",
    "    fitness_func=fitness_func,\n",
    "    allow_duplicate_genes=False, # very important, otherwise we will have duplicate labels in the ordering\n",
    "    num_genes=label_count,\n",
    "\n",
    "    # set up\n",
    "    num_generations=5,\n",
    "    sol_per_pop=3,\n",
    "\n",
    "    # following what the article describes\n",
    "    keep_elitism=1, # also following what the article describes, but we have to double check [TODO]\n",
    "    parent_selection_type=\"rws\", # following what the article describes\n",
    "    # mutation_probability=0.005, # following what the article describes\n",
    "\n",
    "    # the following settings are fixed\n",
    "    # they were chosen for no particular reason\n",
    "    # they are being kept as fixed to simplify the model\n",
    "    num_parents_mating=2,\n",
    "    crossover_type=\"scattered\",\n",
    "    mutation_type=\"random\",\n",
    "    mutation_by_replacement=True,\n",
    "    mutation_num_genes=1,\n",
    ")\n",
    "\n",
    "ga_model.run()\n",
    "\n",
    "solution, _, _ = ga_model.best_solution()\n",
    "display(solution)\n",
    "\n",
    "test_solution(y, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChainWithLOPAndGA():\n",
    "    def __init__(self, base_classifier: Any, num_generations: int = 5, random_state: Optional[int] = None) -> None:\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_generations = num_generations\n",
    "\n",
    "        if random_state is None:\n",
    "            self.random_state = np.random.randint(0, 1000)\n",
    "        else:\n",
    "            self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.probs = calculate_probabilities(y)\n",
    "        self.entropies = calculate_entropies(self.probs)\n",
    "        self.label_count = y.shape[1]\n",
    "\n",
    "        label_space = np.arange(label_count)\n",
    "        solutions_per_population = math.ceil(label_count / 2)\n",
    "\n",
    "        ga_model = pygad.GA( #type:ignore\n",
    "            gene_type=int,\n",
    "            gene_space=label_space,\n",
    "            random_seed=self.random_state,\n",
    "            save_best_solutions=False,\n",
    "            fitness_func=self.model_fitness_func,\n",
    "            allow_duplicate_genes=False, # very important, otherwise we will have duplicate labels in the ordering\n",
    "            num_genes=label_count,\n",
    "\n",
    "            # set up\n",
    "            num_generations=self.num_generations,\n",
    "            sol_per_pop=solutions_per_population,\n",
    "\n",
    "            # following what the article describes\n",
    "            keep_elitism=1, # also following what the article describes, but we have to double check [TODO]\n",
    "            parent_selection_type=\"rws\", # following what the article describes\n",
    "            # mutation_probability=0.005, # following what the article describes\n",
    "\n",
    "            # the following settings are fixed\n",
    "            # they were chosen for no particular reason\n",
    "            # they are being kept as fixed to simplify the model\n",
    "            num_parents_mating=2,\n",
    "            crossover_type=\"scattered\",\n",
    "            mutation_type=\"random\",\n",
    "            mutation_by_replacement=True,\n",
    "            mutation_num_genes=1,\n",
    "        )\n",
    "\n",
    "        ga_model.run()\n",
    "\n",
    "        solution, _, _ = ga_model.best_solution()\n",
    "\n",
    "        best_classifier = ClassifierChain(\n",
    "            classifier=copy.deepcopy(self.base_classifier),\n",
    "            require_dense=[False, True],\n",
    "            order=solution,\n",
    "        )\n",
    "\n",
    "        best_classifier.fit(X, y)\n",
    "\n",
    "        self.best_classifier = best_classifier\n",
    "    \n",
    "    def model_fitness_func(self, ga_instance: Any, solution: Any, solution_idx: Any) -> float:\n",
    "        return self.test_solution(solution)\n",
    "\n",
    "    def test_solution(self, label_order: List[int]) -> float:\n",
    "        if self.probs is None or self.entropies is None:\n",
    "            raise Exception(\"probabilities and entropies must be calculated before testing a solution\")\n",
    "        \n",
    "        lop_matrix = build_lop_matrix(label_order, self.probs, self.entropies)\n",
    "        return calculate_lop(lop_matrix)\n",
    "    \n",
    "    def predict(self, X: Any) -> Any:\n",
    "        if self.best_classifier is None:\n",
    "            raise Exception(\"model was not trained yet\")\n",
    "\n",
    "        return self.best_classifier.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss: 0.2801003344481605\n",
      "f1 score: 0.056223522137844796\n"
     ]
    }
   ],
   "source": [
    "X = datasets[\"scene\"][\"X_train\"]\n",
    "y = datasets[\"scene\"][\"y_train\"]\n",
    "X_test = datasets[\"scene\"][\"X_test\"]\n",
    "y_test = datasets[\"scene\"][\"y_test\"]\n",
    "\n",
    "m = ClassifierChainWithLOPAndGA(RandomForestClassifier(random_state=42), num_generations=20)\n",
    "m.fit(X, y)\n",
    "preds = m.predict(X_test)\n",
    "\n",
    "hamming_loss = metrics.hamming_loss(y_test, preds)\n",
    "f1_score = metrics.f1_score(y_test, preds, average=\"macro\")\n",
    "\n",
    "print(f\"hamming loss: {hamming_loss}\")\n",
    "print(f\"f1 score: {f1_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1196x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 835 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss: 0.5734323432343235\n",
      "f1 score: 0.056981860448637754\n"
     ]
    }
   ],
   "source": [
    "X = datasets[\"emotions\"][\"X_train\"]\n",
    "y = datasets[\"emotions\"][\"y_train\"]\n",
    "X_test = datasets[\"emotions\"][\"X_test\"]\n",
    "y_test = datasets[\"emotions\"][\"y_test\"]\n",
    "\n",
    "m = ClassifierChainWithLOPAndGA(RandomForestClassifier(random_state=42), num_generations=20)\n",
    "m.fit(X, y)\n",
    "other_preds = m.predict(X_test)\n",
    "\n",
    "hamming_loss = metrics.hamming_loss(y_test, other_preds.todense())\n",
    "f1_score = metrics.f1_score(y_test, other_preds, average=\"macro\")\n",
    "\n",
    "print(f\"hamming loss: {hamming_loss}\")\n",
    "print(f\"f1 score: {f1_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
