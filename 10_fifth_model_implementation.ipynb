{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Fifth model implementation\n",
    "\n",
    "Let's dive into the last model, which is a derived version of the model studied in the notebook 9. It uses partial orders instead of full orders in the chain. It is based on the same paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import pygad\n",
    "from typing import List\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Any, Optional\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from numpy.typing import NDArray\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from typing import cast\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. Entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probabilities = Dict[int, Dict[int, float]]\n",
    "\n",
    "def calculate_probabilities(y: NDArray[np.int64]) -> Probabilities:\n",
    "    dense_y = y.todense()\n",
    "\n",
    "    label_count = dense_y.shape[1]\n",
    "    rows_count = dense_y.shape[0]\n",
    "\n",
    "    probs = {}\n",
    "\n",
    "    for label in range(label_count):\n",
    "        probs[label] = {}\n",
    "        y_label_specific = np.asarray(dense_y[:, label]).reshape(-1)\n",
    "        # convert_matrix_to_vector\n",
    "\n",
    "        possible_values = np.unique(y_label_specific)\n",
    "\n",
    "        for value in possible_values:\n",
    "            instances_with_label = np.count_nonzero(y_label_specific == value)\n",
    "            probs[label][value] = instances_with_label / rows_count\n",
    "    \n",
    "    return probs\n",
    "\n",
    "Entropies = Dict[int, float]\n",
    "\n",
    "def calculate_entropies(probabilities: Probabilities) -> Entropies:\n",
    "    entropies = {}\n",
    "\n",
    "    for label, calculated_probabilities in probabilities.items():\n",
    "        results = []\n",
    "        for _, prob in calculated_probabilities.items():\n",
    "            summand = prob * math.log(prob, 2)\n",
    "            results.append(summand)\n",
    "        \n",
    "        entropy = -1 * sum(results)\n",
    "        entropies[label] = entropy\n",
    "\n",
    "    return entropies\n",
    "\n",
    "def calculate_joint_probability(probabilities: Probabilities, label_x: int, label_y: int):\n",
    "    results = []\n",
    "    \n",
    "    for _, prob_i in probabilities[label_x].items():\n",
    "        for _, prob_j in probabilities[label_y].items():\n",
    "            and_prob = prob_i * prob_j\n",
    "\n",
    "            if and_prob > 0:  # avoid taking the log of 0\n",
    "                summand = and_prob * np.log2(and_prob)\n",
    "                results.append(summand)\n",
    "    \n",
    "    joint_probability = -1 * sum(results)\n",
    "    return joint_probability\n",
    "\n",
    "def calculate_conditional_entropy(probabilities: Probabilities, entropies: Entropies, label_x: int, label_y: int):\n",
    "    joint_entropy = calculate_joint_probability(probabilities, label_x, label_y)\n",
    "    entropy = entropies[label_y]\n",
    "    return joint_entropy - entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOPMatrix = Dict[int, Dict[int, float]]\n",
    "\n",
    "def build_lop_matrix(\n",
    "    label_order: List[int],\n",
    "    probabilities: Probabilities,\n",
    "    entropies: Entropies\n",
    ") -> LOPMatrix:\n",
    "    matrix = {}\n",
    "\n",
    "    for row_i in label_order:\n",
    "        matrix[row_i] = {}\n",
    "        for row_j in label_order:\n",
    "            if row_i == row_j:\n",
    "                matrix[row_i][row_j] = 0\n",
    "                # this is to match the table described in the paper\n",
    "                # but in reality we _have_ a >0 conditional entropy for a label with itself\n",
    "                continue\n",
    "\n",
    "            cond_entropy = calculate_conditional_entropy(probabilities, entropies, row_i, row_j)\n",
    "            matrix[row_i][row_j] = cond_entropy\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def calculate_lop(lop_matrix: LOPMatrix) -> float:\n",
    "    matrix_size_n = len(lop_matrix)\n",
    "    lop_df = pd.DataFrame(lop_matrix)\n",
    "\n",
    "    upper_triangle_sum = 0\n",
    "    for row_position in range(matrix_size_n):\n",
    "        for column_position in range(matrix_size_n):\n",
    "            if column_position > row_position:\n",
    "                conditional_probability = lop_df.iloc[row_position, column_position]\n",
    "                upper_triangle_sum += cast(float, conditional_probability)\n",
    "                # the conversion to a dataframe is not necessary\n",
    "                # but makes it easier to find the element we want\n",
    "                # by their order in the rows or columns\n",
    "                # instead of the actual column or row index\n",
    "    \n",
    "    return upper_triangle_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5. New entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(probabilities: Probabilities, entropies: Entropies, label_x: int, label_y: int):\n",
    "    entropy = entropies[label_x]\n",
    "    conditional_entropy = calculate_conditional_entropy(probabilities, entropies, label_x, label_y)\n",
    "\n",
    "    # return entropy - conditional_entropy\n",
    "\n",
    "    a = entropies[label_x]\n",
    "    b = entropies[label_y]\n",
    "\n",
    "    calculate_joint_entropy = calculate_joint_probability(probabilities, label_x, label_y)\n",
    "\n",
    "    return a + b - calculate_joint_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== mutual information ===\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.440892e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  0.000000e+00  2.220446e-16 -2.220446e-16  2.220446e-16  0.000000e+00   \n",
       "1  2.220446e-16  0.000000e+00  0.000000e+00  0.000000e+00  2.220446e-16   \n",
       "2  0.000000e+00  0.000000e+00 -4.440892e-16 -2.220446e-16 -2.220446e-16   \n",
       "3  2.220446e-16  0.000000e+00 -2.220446e-16  0.000000e+00  0.000000e+00   \n",
       "4  0.000000e+00  2.220446e-16 -2.220446e-16  0.000000e+00  0.000000e+00   \n",
       "5  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "              5  \n",
       "0  0.000000e+00  \n",
       "1  2.220446e-16  \n",
       "2  0.000000e+00  \n",
       "3  2.220446e-16  \n",
       "4  0.000000e+00  \n",
       "5  0.000000e+00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = calculate_probabilities(datasets[\"emotions\"][\"y\"])\n",
    "entropies = calculate_entropies(probs)\n",
    "\n",
    "print(\"=== mutual information ===\")\n",
    "print(mutual_information(probs, entropies, 2, 0))\n",
    "\n",
    "res = []\n",
    "for i in range(len(probs)):\n",
    "    res.append([])\n",
    "    for j in range(len(probs)):\n",
    "        res[i].append(mutual_information(probs, entropies, i, j))\n",
    "\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6. Results so far\n",
    "\n",
    "The results are weird because they are very, very small. And some of them are negative. But [this Wikipedia page](https://en.wikipedia.org/wiki/Mutual_information) tells that the mutual information **cannot** be negative.\n",
    "\n",
    "It might be because my calculations of the entropy are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7. Checking the results by looking for other implementations\n",
    "\n",
    "I found [this implementation](https://github.com/pafoster/pyitlib). Let's see if it works as expected.\n",
    "\n",
    "I also found [this other implementation](https://github.com/nikdon/pyEntropy), but it seems limited; and [this other from scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html), but it also seems limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyitlib\n",
      "  Downloading pyitlib-0.2.3.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=0.20.2 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.22.4)\n",
      "Collecting scikit-learn<=0.24,>=0.16.0 (from pyitlib)\n",
      "  Downloading scikit_learn-0.24.0-cp39-cp39-win_amd64.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.6.2)\n",
      "Collecting future>=0.16.0 (from pyitlib)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ------------------------------------- 840.9/840.9 kB 26.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.20.2->pyitlib) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.20.2->pyitlib) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn<=0.24,>=0.16.0->pyitlib) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn<=0.24,>=0.16.0->pyitlib) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.20.2->pyitlib) (1.15.0)\n",
      "Building wheels for collected packages: pyitlib, future\n",
      "  Building wheel for pyitlib (setup.py): started\n",
      "  Building wheel for pyitlib (setup.py): finished with status 'done'\n",
      "  Created wheel for pyitlib: filename=pyitlib-0.2.3-py3-none-any.whl size=29367 sha256=b37a01ce175782c490f57abcd4816ad5fa382d2a3fde2ef0ec9a5cb244871996\n",
      "  Stored in directory: c:\\users\\edgard\\appdata\\local\\pip\\cache\\wheels\\c4\\d1\\dc\\ac69412c0dc60ee3fc207f07b6f15abda55c70b7b3e96315aa\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492036 sha256=8ed46af11f690042729b9ea7ba26b7b7b7d91ca5e4dfb370c0b555012c202b3e\n",
      "  Stored in directory: c:\\users\\edgard\\appdata\\local\\pip\\cache\\wheels\\bf\\5d\\6a\\2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built pyitlib future\n",
      "Installing collected packages: future, scikit-learn, pyitlib\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "Successfully installed future-0.18.3 pyitlib-0.2.3 scikit-learn-0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Edgard\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyitlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyitlib import discrete_random_variable as drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
