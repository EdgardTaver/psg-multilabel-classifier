{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Fifth model implementation\n",
    "\n",
    "Let's dive into the last model, which is a derived version of the model studied in the notebook 9. It uses partial orders instead of full orders in the chain. It is based on the same paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "import pygad\n",
    "from typing import List\n",
    "import sklearn.metrics as metrics\n",
    "from typing import Any, Optional\n",
    "import copy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from numpy.typing import NDArray\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from typing import cast\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting dataset `scene`\n",
      "scene:undivided - exists, not redownloading\n",
      "scene:train - exists, not redownloading\n",
      "scene:test - exists, not redownloading\n",
      "getting dataset `emotions`\n",
      "emotions:undivided - exists, not redownloading\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "getting dataset `birds`\n",
      "birds:undivided - exists, not redownloading\n",
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "===\n",
      "information for dataset `scene`\n",
      "rows: 2407, labels: 6\n",
      "===\n",
      "information for dataset `emotions`\n",
      "rows: 593, labels: 6\n",
      "===\n",
      "information for dataset `birds`\n",
      "rows: 645, labels: 19\n"
     ]
    }
   ],
   "source": [
    "desired_datasets = [\"scene\", \"emotions\", \"birds\"]\n",
    "\n",
    "datasets = {}\n",
    "for dataset_name in desired_datasets:\n",
    "    print(f\"getting dataset `{dataset_name}`\")\n",
    "    \n",
    "    full_dataset = load_dataset(dataset_name, \"undivided\")\n",
    "    X, y, _, _ = full_dataset\n",
    "\n",
    "    train_dataset = load_dataset(dataset_name, \"train\")\n",
    "    X_train, y_train, _, _ = train_dataset\n",
    "\n",
    "    test_dataset = load_dataset(dataset_name, \"test\")\n",
    "    X_test, y_test, _, _ = test_dataset\n",
    "\n",
    "    datasets[dataset_name] = {\n",
    "        \"X\": X,\n",
    "        \"y\": y,\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"rows\": X.shape[0],\n",
    "        \"labels_count\": y.shape[1]\n",
    "    }\n",
    "\n",
    "for name, info in datasets.items():\n",
    "    print(\"===\")\n",
    "    print(f\"information for dataset `{name}`\")\n",
    "    print(f\"rows: {info['rows']}, labels: {info['labels_count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3. Entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Probabilities = Dict[int, Dict[int, float]]\n",
    "\n",
    "def calculate_probabilities(y: NDArray[np.int64]) -> Probabilities:\n",
    "    dense_y = y.todense()\n",
    "\n",
    "    label_count = dense_y.shape[1]\n",
    "    rows_count = dense_y.shape[0]\n",
    "\n",
    "    probs = {}\n",
    "\n",
    "    for label in range(label_count):\n",
    "        probs[label] = {}\n",
    "        y_label_specific = np.asarray(dense_y[:, label]).reshape(-1)\n",
    "        # convert_matrix_to_vector\n",
    "\n",
    "        possible_values = np.unique(y_label_specific)\n",
    "\n",
    "        for value in possible_values:\n",
    "            instances_with_label = np.count_nonzero(y_label_specific == value)\n",
    "            probs[label][value] = instances_with_label / rows_count\n",
    "    \n",
    "    return probs\n",
    "\n",
    "Entropies = Dict[int, float]\n",
    "\n",
    "def calculate_entropies(probabilities: Probabilities) -> Entropies:\n",
    "    entropies = {}\n",
    "\n",
    "    for label, calculated_probabilities in probabilities.items():\n",
    "        results = []\n",
    "        for _, prob in calculated_probabilities.items():\n",
    "            summand = prob * math.log(prob, 2)\n",
    "            results.append(summand)\n",
    "        \n",
    "        entropy = -1 * sum(results)\n",
    "        entropies[label] = entropy\n",
    "\n",
    "    return entropies\n",
    "\n",
    "def calculate_joint_probability(probabilities: Probabilities, label_x: int, label_y: int):\n",
    "    results = []\n",
    "    \n",
    "    for _, prob_i in probabilities[label_x].items():\n",
    "        for _, prob_j in probabilities[label_y].items():\n",
    "            and_prob = prob_i * prob_j\n",
    "\n",
    "            if and_prob > 0:  # avoid taking the log of 0\n",
    "                summand = and_prob * np.log2(and_prob)\n",
    "                results.append(summand)\n",
    "    \n",
    "    joint_probability = -1 * sum(results)\n",
    "    return joint_probability\n",
    "\n",
    "def calculate_conditional_entropy(probabilities: Probabilities, entropies: Entropies, label_x: int, label_y: int):\n",
    "    joint_entropy = calculate_joint_probability(probabilities, label_x, label_y)\n",
    "    entropy = entropies[label_y]\n",
    "    return joint_entropy - entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOPMatrix = Dict[int, Dict[int, float]]\n",
    "\n",
    "def build_lop_matrix(\n",
    "    label_order: List[int],\n",
    "    probabilities: Probabilities,\n",
    "    entropies: Entropies\n",
    ") -> LOPMatrix:\n",
    "    matrix = {}\n",
    "\n",
    "    for row_i in label_order:\n",
    "        matrix[row_i] = {}\n",
    "        for row_j in label_order:\n",
    "            if row_i == row_j:\n",
    "                matrix[row_i][row_j] = 0\n",
    "                # this is to match the table described in the paper\n",
    "                # but in reality we _have_ a >0 conditional entropy for a label with itself\n",
    "                continue\n",
    "\n",
    "            cond_entropy = calculate_conditional_entropy(probabilities, entropies, row_i, row_j)\n",
    "            matrix[row_i][row_j] = cond_entropy\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def calculate_lop(lop_matrix: LOPMatrix) -> float:\n",
    "    matrix_size_n = len(lop_matrix)\n",
    "    lop_df = pd.DataFrame(lop_matrix)\n",
    "\n",
    "    upper_triangle_sum = 0\n",
    "    for row_position in range(matrix_size_n):\n",
    "        for column_position in range(matrix_size_n):\n",
    "            if column_position > row_position:\n",
    "                conditional_probability = lop_df.iloc[row_position, column_position]\n",
    "                upper_triangle_sum += cast(float, conditional_probability)\n",
    "                # the conversion to a dataframe is not necessary\n",
    "                # but makes it easier to find the element we want\n",
    "                # by their order in the rows or columns\n",
    "                # instead of the actual column or row index\n",
    "    \n",
    "    return upper_triangle_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5. New entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(probabilities: Probabilities, entropies: Entropies, label_x: int, label_y: int):\n",
    "    entropy = entropies[label_x]\n",
    "    conditional_entropy = calculate_conditional_entropy(probabilities, entropies, label_x, label_y)\n",
    "\n",
    "    # return entropy - conditional_entropy\n",
    "\n",
    "    a = entropies[label_x]\n",
    "    b = entropies[label_y]\n",
    "\n",
    "    calculate_joint_entropy = calculate_joint_probability(probabilities, label_x, label_y)\n",
    "\n",
    "    return a + b - calculate_joint_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== mutual information ===\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.440892e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  0.000000e+00  2.220446e-16 -2.220446e-16  2.220446e-16  0.000000e+00   \n",
       "1  2.220446e-16  0.000000e+00  0.000000e+00  0.000000e+00  2.220446e-16   \n",
       "2  0.000000e+00  0.000000e+00 -4.440892e-16 -2.220446e-16 -2.220446e-16   \n",
       "3  2.220446e-16  0.000000e+00 -2.220446e-16  0.000000e+00  0.000000e+00   \n",
       "4  0.000000e+00  2.220446e-16 -2.220446e-16  0.000000e+00  0.000000e+00   \n",
       "5  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "              5  \n",
       "0  0.000000e+00  \n",
       "1  2.220446e-16  \n",
       "2  0.000000e+00  \n",
       "3  2.220446e-16  \n",
       "4  0.000000e+00  \n",
       "5  0.000000e+00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = calculate_probabilities(datasets[\"emotions\"][\"y\"])\n",
    "entropies = calculate_entropies(probs)\n",
    "\n",
    "print(\"=== mutual information ===\")\n",
    "print(mutual_information(probs, entropies, 2, 0))\n",
    "\n",
    "res = []\n",
    "for i in range(len(probs)):\n",
    "    res.append([])\n",
    "    for j in range(len(probs)):\n",
    "        res[i].append(mutual_information(probs, entropies, i, j))\n",
    "\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6. Results so far\n",
    "\n",
    "The results are weird because they are very, very small. And some of them are negative. But [this Wikipedia page](https://en.wikipedia.org/wiki/Mutual_information) tells that the mutual information **cannot** be negative.\n",
    "\n",
    "It might be because my calculations of the entropy are wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7. Checking the results by looking for other implementations\n",
    "\n",
    "I found [this implementation](https://github.com/pafoster/pyitlib). Let's see if it works as expected.\n",
    "\n",
    "I also found [this other implementation](https://github.com/nikdon/pyEntropy), but it seems limited; and [this other from scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html), but it also seems limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyitlib\n",
      "  Downloading pyitlib-0.2.3.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=0.20.2 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.22.4)\n",
      "Collecting scikit-learn<=0.24,>=0.16.0 (from pyitlib)\n",
      "  Downloading scikit_learn-0.24.0-cp39-cp39-win_amd64.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyitlib) (1.6.2)\n",
      "Collecting future>=0.16.0 (from pyitlib)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ------------------------------------- 840.9/840.9 kB 26.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.20.2->pyitlib) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.20.2->pyitlib) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn<=0.24,>=0.16.0->pyitlib) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn<=0.24,>=0.16.0->pyitlib) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\edgard\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.20.2->pyitlib) (1.15.0)\n",
      "Building wheels for collected packages: pyitlib, future\n",
      "  Building wheel for pyitlib (setup.py): started\n",
      "  Building wheel for pyitlib (setup.py): finished with status 'done'\n",
      "  Created wheel for pyitlib: filename=pyitlib-0.2.3-py3-none-any.whl size=29367 sha256=b37a01ce175782c490f57abcd4816ad5fa382d2a3fde2ef0ec9a5cb244871996\n",
      "  Stored in directory: c:\\users\\edgard\\appdata\\local\\pip\\cache\\wheels\\c4\\d1\\dc\\ac69412c0dc60ee3fc207f07b6f15abda55c70b7b3e96315aa\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492036 sha256=8ed46af11f690042729b9ea7ba26b7b7b7d91ca5e4dfb370c0b555012c202b3e\n",
      "  Stored in directory: c:\\users\\edgard\\appdata\\local\\pip\\cache\\wheels\\bf\\5d\\6a\\2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built pyitlib future\n",
      "Installing collected packages: future, scikit-learn, pyitlib\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "Successfully installed future-0.18.3 pyitlib-0.2.3 scikit-learn-0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Edgard\\AppData\\Local\\Programs\\Python\\Python39\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyitlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyitlib import discrete_random_variable as drv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([0,1,0,1])\n",
    "drv.entropy([0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for label 0 the entropy is 0.8709543977484913\n",
      "for label 1 the entropy is 0.855358883986916\n",
      "for label 2 the entropy is 0.9913156991505125\n",
      "for label 3 the entropy is 0.8106092437567831\n",
      "for label 4 the entropy is 0.8599154189768907\n",
      "for label 5 the entropy is 0.9029822958790428\n"
     ]
    }
   ],
   "source": [
    "y = datasets[\"emotions\"][\"y\"]\n",
    "dense_y = y.todense()\n",
    "\n",
    "for label in range(dense_y.shape[1]):\n",
    "    y_label_specific = np.asarray(dense_y[:, label]).reshape(-1)\n",
    "    e = drv.entropy(y_label_specific.tolist())\n",
    "\n",
    "    print(f\"for label {label} the entropy is {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.8709543977484913,\n",
       " 1: 0.8553588839869162,\n",
       " 2: 0.9913156991505125,\n",
       " 3: 0.8106092437567831,\n",
       " 4: 0.8599154189768907,\n",
       " 5: 0.9029822958790428}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far my calculation for entropy is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (0, 0), we got 0.0\n",
      "for (0, 1), we got 0.8681775017071309\n",
      "for (0, 2), we got 0.6805721429652296\n",
      "for (0, 3), we got 0.7234043892136215\n",
      "for (0, 4), we got 0.7806134241301019\n",
      "for (0, 5), we got 0.8110675830696776\n",
      "for (1, 0), we got 0.8525819879455556\n",
      "for (1, 1), we got 0.0\n",
      "for (1, 2), we got 0.8433595973068642\n",
      "for (1, 3), we got 0.774297908543917\n",
      "for (1, 4), we got 0.7055354159044847\n",
      "for (1, 5), we got 0.7619971777464194\n",
      "for (2, 0), we got 0.8009334443672507\n",
      "for (2, 1), we got 0.9793164124704608\n",
      "for (2, 2), we got 0.0\n",
      "for (2, 3), we got 0.9262497452773448\n",
      "for (2, 4), we got 0.9746674787371223\n",
      "for (2, 5), we got 0.7172239534657157\n",
      "for (3, 0), we got 0.6630592352219131\n",
      "for (3, 1), we got 0.7295482683137842\n",
      "for (3, 2), we got 0.7455432898836154\n",
      "for (3, 3), we got 0.0\n",
      "for (3, 4), we got 0.6091876963156833\n",
      "for (3, 5), we got 0.6699847819811764\n",
      "for (4, 0), we got 0.7695744453585014\n",
      "for (4, 1), we got 0.7100919508944596\n",
      "for (4, 2), we got 0.8432671985635005\n",
      "for (4, 3), we got 0.6584938715357909\n",
      "for (4, 4), we got 0.0\n",
      "for (4, 5), we got 0.8010033262512426\n",
      "for (5, 0), we got 0.8430954812002294\n",
      "for (5, 1), we got 0.8096205896385462\n",
      "for (5, 2), we got 0.6288905501942459\n",
      "for (5, 3), we got 0.762357834103436\n",
      "for (5, 4), we got 0.8440702031533946\n",
      "for (5, 5), we got 0.0\n"
     ]
    }
   ],
   "source": [
    "for label_x in range(dense_y.shape[1]):\n",
    "    for label_y in range(dense_y.shape[1]):\n",
    "        y_label_specific_x = np.asarray(dense_y[:, label_x]).reshape(-1)\n",
    "        y_label_specific_y = np.asarray(dense_y[:, label_y]).reshape(-1)\n",
    "        \n",
    "        e = drv.entropy_conditional(y_label_specific_x.tolist(), y_label_specific_y.tolist())\n",
    "\n",
    "        print(f\"for ({label_x}, {label_y}), we got {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for (0, 0), we got 0.8709543977484913\n",
      "for (0, 1), we got 0.0027768960413603327\n",
      "for (0, 2), we got 0.19038225478326165\n",
      "for (0, 3), we got 0.14755000853486977\n",
      "for (0, 4), we got 0.09034097361838933\n",
      "for (0, 5), we got 0.05988681467881363\n",
      "for (1, 0), we got 0.0027768960413603327\n",
      "for (1, 1), we got 0.855358883986916\n",
      "for (1, 2), we got 0.01199928668005179\n",
      "for (1, 3), we got 0.08106097544299895\n",
      "for (1, 4), we got 0.1498234680824313\n",
      "for (1, 5), we got 0.09336170624049656\n",
      "for (2, 0), we got 0.19038225478326187\n",
      "for (2, 1), we got 0.01199928668005179\n",
      "for (2, 2), we got 0.9913156991505125\n",
      "for (2, 3), we got 0.06506595387316771\n",
      "for (2, 4), we got 0.016648220413390202\n",
      "for (2, 5), we got 0.2740917456847969\n",
      "for (3, 0), we got 0.14755000853487\n",
      "for (3, 1), we got 0.08106097544299895\n",
      "for (3, 2), we got 0.06506595387316771\n",
      "for (3, 3), we got 0.8106092437567831\n",
      "for (3, 4), we got 0.20142154744109986\n",
      "for (3, 5), we got 0.14062446177560672\n",
      "for (4, 0), we got 0.09034097361838933\n",
      "for (4, 1), we got 0.14982346808243108\n",
      "for (4, 2), we got 0.016648220413390202\n",
      "for (4, 3), we got 0.20142154744109986\n",
      "for (4, 4), we got 0.8599154189768907\n",
      "for (4, 5), we got 0.058912092725648124\n",
      "for (5, 0), we got 0.059886814678813405\n",
      "for (5, 1), we got 0.09336170624049656\n",
      "for (5, 2), we got 0.2740917456847969\n",
      "for (5, 3), we got 0.14062446177560672\n",
      "for (5, 4), we got 0.058912092725648124\n",
      "for (5, 5), we got 0.9029822958790428\n"
     ]
    }
   ],
   "source": [
    "for label_x in range(dense_y.shape[1]):\n",
    "    for label_y in range(dense_y.shape[1]):\n",
    "        y_label_specific_x = np.asarray(dense_y[:, label_x]).reshape(-1)\n",
    "        y_label_specific_y = np.asarray(dense_y[:, label_y]).reshape(-1)\n",
    "        \n",
    "        e = drv.information_mutual(y_label_specific_x.tolist(), y_label_specific_y.tolist())\n",
    "\n",
    "        print(f\"for ({label_x}, {label_y}), we got {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations for these other \"entropy properties\" are very different to those of my own implementation. **My own implementation is clearly wrong**. I will adopt this new library.\n",
    "\n",
    "**Something else that is nice is that this calculation is already resulting in zero when we test a label against itself**. This is good because it means that the entropy is zero when the label is fully determined by the other label. And it matches exactly what the article describes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 Re-implementing the fourth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConditionalEntropies = List[List[float]]\n",
    "\n",
    "def calculate_conditional_entropies(y: Any) -> ConditionalEntropies:\n",
    "    dense_y = y.todense()\n",
    "\n",
    "    label_count = dense_y.shape[1]\n",
    "\n",
    "    results = []\n",
    "    for label_x in range(label_count):\n",
    "        results.append([])\n",
    "        for label_y in range(label_count):\n",
    "            y_label_specific_x = np.asarray(dense_y[:, label_x]).reshape(-1)\n",
    "            y_label_specific_y = np.asarray(dense_y[:, label_y]).reshape(-1)\n",
    "            \n",
    "            conditional_entropy = drv.entropy_conditional(y_label_specific_x.tolist(), y_label_specific_y.tolist())\n",
    "            results[label_x].append(float(conditional_entropy))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.8681775017071309,\n",
       "  0.6805721429652296,\n",
       "  0.7234043892136215,\n",
       "  0.7806134241301019,\n",
       "  0.8110675830696776],\n",
       " [0.8525819879455556,\n",
       "  0.0,\n",
       "  0.8433595973068642,\n",
       "  0.774297908543917,\n",
       "  0.7055354159044847,\n",
       "  0.7619971777464194],\n",
       " [0.8009334443672507,\n",
       "  0.9793164124704608,\n",
       "  0.0,\n",
       "  0.9262497452773448,\n",
       "  0.9746674787371223,\n",
       "  0.7172239534657157],\n",
       " [0.6630592352219131,\n",
       "  0.7295482683137842,\n",
       "  0.7455432898836154,\n",
       "  0.0,\n",
       "  0.6091876963156833,\n",
       "  0.6699847819811764],\n",
       " [0.7695744453585014,\n",
       "  0.7100919508944596,\n",
       "  0.8432671985635005,\n",
       "  0.6584938715357909,\n",
       "  0.0,\n",
       "  0.8010033262512426],\n",
       " [0.8430954812002294,\n",
       "  0.8096205896385462,\n",
       "  0.6288905501942459,\n",
       "  0.762357834103436,\n",
       "  0.8440702031533946,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_entropies = calculate_conditional_entropies(datasets[\"emotions\"][\"y\"])\n",
    "conditional_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680572</td>\n",
       "      <td>0.843360</td>\n",
       "      <td>0.745543</td>\n",
       "      <td>0.628891</td>\n",
       "      <td>0.843267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.852582</td>\n",
       "      <td>0.663059</td>\n",
       "      <td>0.843095</td>\n",
       "      <td>0.769574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.979316</td>\n",
       "      <td>0.868178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729548</td>\n",
       "      <td>0.809621</td>\n",
       "      <td>0.710092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926250</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.774298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.762358</td>\n",
       "      <td>0.658494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.717224</td>\n",
       "      <td>0.811068</td>\n",
       "      <td>0.761997</td>\n",
       "      <td>0.669985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.780613</td>\n",
       "      <td>0.705535</td>\n",
       "      <td>0.609188</td>\n",
       "      <td>0.844070</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2         0         1         3         5         4\n",
       "2  0.000000  0.680572  0.843360  0.745543  0.628891  0.843267\n",
       "0  0.800933  0.000000  0.852582  0.663059  0.843095  0.769574\n",
       "1  0.979316  0.868178  0.000000  0.729548  0.809621  0.710092\n",
       "3  0.926250  0.723404  0.774298  0.000000  0.762358  0.658494\n",
       "5  0.717224  0.811068  0.761997  0.669985  0.000000  0.801003\n",
       "4  0.974667  0.780613  0.705535  0.609188  0.844070  0.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_lop_matrix(\n",
    "    label_order: List[int],\n",
    "    conditional_entropies: ConditionalEntropies\n",
    ") -> LOPMatrix:\n",
    "    matrix = {}\n",
    "\n",
    "    for row_i in label_order:\n",
    "        matrix[row_i] = {}\n",
    "        for row_j in label_order:\n",
    "            conditional_entropy = conditional_entropies[row_i][row_j]\n",
    "            matrix[row_i][row_j] = conditional_entropy\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "\n",
    "pd.DataFrame(build_lop_matrix([2, 0, 1, 3, 5, 4], conditional_entropies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lop_matrix(\n",
    "    label_order: List[int],\n",
    "    conditional_entropies: ConditionalEntropies\n",
    ") -> LOPMatrix:\n",
    "    matrix = {}\n",
    "\n",
    "    for row_i in label_order:\n",
    "        matrix[row_i] = {}\n",
    "        for row_j in label_order:\n",
    "            conditional_entropy = conditional_entropies[row_i][row_j]\n",
    "            matrix[row_i][row_j] = conditional_entropy\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "def calculate_lop(lop_matrix: LOPMatrix) -> float:\n",
    "    matrix_size_n = len(lop_matrix)\n",
    "    lop_df = pd.DataFrame(lop_matrix)\n",
    "\n",
    "    upper_triangle_sum = 0\n",
    "    for row_position in range(matrix_size_n):\n",
    "        for column_position in range(matrix_size_n):\n",
    "            if column_position > row_position:\n",
    "                conditional_probability = lop_df.iloc[row_position, column_position]\n",
    "                upper_triangle_sum += cast(float, conditional_probability)\n",
    "                # the conversion to a data frame is not necessary\n",
    "                # but makes it easier to find the element we want\n",
    "                # by their order in the rows or columns\n",
    "                # instead of the actual column or row index\n",
    "    \n",
    "    return upper_triangle_sum\n",
    "\n",
    "class FixedClassifierChainWithLOPAndGA():\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_classifier: Any,\n",
    "        num_generations: int = 5,\n",
    "        random_state: Optional[int] = None\n",
    "    ) -> None:\n",
    "        self.base_classifier = base_classifier\n",
    "        self.num_generations = num_generations\n",
    "\n",
    "        if random_state is None:\n",
    "            self.random_state = np.random.randint(0, 1000)\n",
    "        else:\n",
    "            self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.conditional_entropies = calculate_conditional_entropies(y)\n",
    "        \n",
    "        label_count = y.shape[1]\n",
    "        label_space = np.arange(label_count)\n",
    "        # solutions_per_population = math.ceil(label_count / 2)\n",
    "        solutions_per_population = 50\n",
    "\n",
    "        ga_model = pygad.GA( #type:ignore\n",
    "            gene_type=int,\n",
    "            gene_space=label_space,\n",
    "            random_seed=self.random_state,\n",
    "            save_best_solutions=False,\n",
    "            fitness_func=self.model_fitness_func,\n",
    "            allow_duplicate_genes=False, # very important, otherwise we will have duplicate labels in the ordering\n",
    "            num_genes=label_count,\n",
    "\n",
    "            # set up\n",
    "            num_generations=self.num_generations,\n",
    "            sol_per_pop=solutions_per_population,\n",
    "\n",
    "            # following what the article describes\n",
    "            keep_elitism=5,\n",
    "            parent_selection_type=\"rws\",\n",
    "            num_parents_mating=2,\n",
    "            crossover_probability=0.9,\n",
    "            crossover_type=\"two_points\",\n",
    "            mutation_type=\"swap\",\n",
    "            mutation_probability=0.01,\n",
    "        )\n",
    "\n",
    "        ga_model.run()\n",
    "\n",
    "        solution, _, _ = ga_model.best_solution()\n",
    "\n",
    "        best_classifier = FixedClassifierChain(\n",
    "            base_classifier=copy.deepcopy(self.base_classifier),\n",
    "            order=solution,\n",
    "        )\n",
    "\n",
    "        best_classifier.fit(X, y)\n",
    "\n",
    "        self.best_classifier = best_classifier\n",
    "    \n",
    "    def model_fitness_func(self, ga_instance: Any, solution: Any, solution_idx: Any) -> float:\n",
    "        return self.test_solution(solution)\n",
    "\n",
    "    def test_solution(self, label_order: List[int]) -> float:\n",
    "        if self.probabilities is None or self.entropies is None:\n",
    "            raise Exception(\"probabilities and entropies must be calculated before testing a solution\")\n",
    "        \n",
    "        lop_matrix = build_lop_matrix(label_order, self.probabilities, self.entropies)\n",
    "        return calculate_lop(lop_matrix)\n",
    "    \n",
    "    def predict(self, X: Any) -> Any:\n",
    "        if self.best_classifier is None:\n",
    "            raise Exception(\"model was not trained yet\")\n",
    "\n",
    "        return self.best_classifier.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
