{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First Model Experiments\n",
    "\n",
    "Experiments to handle the very first model for my thesis.\n",
    "T\n",
    "The plan is to implement a **basic stacking algorithm** using the existing Binary Relevance implementation, found in the `scikit-multilearn` library, and then implement the actual new model, which runs a specific feature selection process between each layer of the stacking algorithm.\n",
    "\n",
    "The initial experimentation follows [this page](http://scikit.ml/tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.dataset import load_dataset, available_data_sets\n",
    "from sklearn.svm import SVC\n",
    "from skmultilearn.base.problem_transformation import ProblemTransformationBase\n",
    "from typing import List, Optional, Any, Tuple, Dict\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Setting up a stacking classifier\n",
    "\n",
    "At first, let's build a simple stacking implementation, so we can have a baseline to compare with the specialized stacking implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('bibtex', 'undivided'): ['5c1e474c2fd026519aec931a26ad18a6',\n",
       "              'bibtex-undivided.scikitml.bz2'],\n",
       "             ('bibtex', 'test'): ['d250caa297d060374f59318ad6b93771',\n",
       "              'bibtex-test.scikitml.bz2'],\n",
       "             ('bibtex', 'train'): ['1dd15daca7b8b2c17d692bdadce5dc31',\n",
       "              'bibtex-train.scikitml.bz2'],\n",
       "             ('birds', 'undivided'): ['1da06f4ae896800547dabf89044584e1',\n",
       "              'birds-undivided.scikitml.bz2'],\n",
       "             ('birds', 'test'): ['77fbfcc66d77040d3806c2a5ea4ff829',\n",
       "              'birds-test.scikitml.bz2'],\n",
       "             ('birds', 'train'): ['5c2bacaa5506e904b6501cc50ddfefe2',\n",
       "              'birds-train.scikitml.bz2'],\n",
       "             ('Corel5k', 'undivided'): ['062ea897821608035748a2a3b200d382',\n",
       "              'Corel5k-undivided.scikitml.bz2'],\n",
       "             ('Corel5k', 'test'): ['cb91444418a2f8b9814d10d4696af9f0',\n",
       "              'Corel5k-test.scikitml.bz2'],\n",
       "             ('Corel5k', 'train'): ['1863ec41b872f75b5f07bdc4cdc419fd',\n",
       "              'Corel5k-train.scikitml.bz2'],\n",
       "             ('delicious', 'undivided'): ['45abc065f123f2ac4d4f6ea5c5a5f940',\n",
       "              'delicious-undivided.scikitml.bz2'],\n",
       "             ('delicious', 'test'): ['6dfb4b0c2ae56010ba0166c9c592cfb6',\n",
       "              'delicious-test.scikitml.bz2'],\n",
       "             ('delicious', 'train'): ['31964bf875bc359ed1460536cb85859e',\n",
       "              'delicious-train.scikitml.bz2'],\n",
       "             ('emotions', 'undivided'): ['569a6c4dad0fdd2d470b9ad41fd18b6b',\n",
       "              'emotions-undivided.scikitml.bz2'],\n",
       "             ('emotions', 'test'): ['0090d9d829f20f2d112dbf942511b199',\n",
       "              'emotions-test.scikitml.bz2'],\n",
       "             ('emotions', 'train'): ['d558ed3cca99742cf7e80731c4c04b8e',\n",
       "              'emotions-train.scikitml.bz2'],\n",
       "             ('enron', 'undivided'): ['54b5f5d53695920274d5b8e2ca986513',\n",
       "              'enron-undivided.scikitml.bz2'],\n",
       "             ('enron', 'test'): ['37a240406757efc03c0cac474d5438e9',\n",
       "              'enron-test.scikitml.bz2'],\n",
       "             ('enron', 'train'): ['0fc03a1837e9e65b68f5d6f849b1773f',\n",
       "              'enron-train.scikitml.bz2'],\n",
       "             ('genbase', 'undivided'): ['46af04a7f0554eb2e64a9fcf2b9d3a9c',\n",
       "              'genbase-undivided.scikitml.bz2'],\n",
       "             ('genbase', 'test'): ['129876a9411ed1adf2366c3c7f6c1dd8',\n",
       "              'genbase-test.scikitml.bz2'],\n",
       "             ('genbase', 'train'): ['a674eb31684fe824d80025c414b884d4',\n",
       "              'genbase-train.scikitml.bz2'],\n",
       "             ('mediamill', 'undivided'): ['e2f91f4ed10df70414622a1001e0c447',\n",
       "              'mediamill-undivided.scikitml.bz2'],\n",
       "             ('mediamill', 'test'): ['d17a675cf8c78674557f000739f893a7',\n",
       "              'mediamill-test.scikitml.bz2'],\n",
       "             ('mediamill', 'train'): ['a96c5d0ce916d724397b793e75baa0cb',\n",
       "              'mediamill-train.scikitml.bz2'],\n",
       "             ('medical', 'undivided'): ['b3eac7e58595898904a8e7aa148b259c',\n",
       "              'medical-undivided.scikitml.bz2'],\n",
       "             ('medical', 'test'): ['cd91418a6a616db88529482729cbb60b',\n",
       "              'medical-test.scikitml.bz2'],\n",
       "             ('medical', 'train'): ['cb91bcdba133b33ec53195a345e3ebba',\n",
       "              'medical-train.scikitml.bz2'],\n",
       "             ('rcv1subset1', 'undivided'): ['2d1906310260144a87f5de89edb402b0',\n",
       "              'rcv1subset1-undivided.scikitml.bz2'],\n",
       "             ('rcv1subset1', 'test'): ['30d0c3b155ece588073c1a7a609a2b7b',\n",
       "              'rcv1subset1-test.scikitml.bz2'],\n",
       "             ('rcv1subset1', 'train'): ['2482c6e57ff578b8b9f429df140c3866',\n",
       "              'rcv1subset1-train.scikitml.bz2'],\n",
       "             ('rcv1subset2', 'undivided'): ['e42a7f75eafd5adfe6452454c6cffee2',\n",
       "              'rcv1subset2-undivided.scikitml.bz2'],\n",
       "             ('rcv1subset2', 'test'): ['a16a22a36912d3388b94c2aba77d4462',\n",
       "              'rcv1subset2-test.scikitml.bz2'],\n",
       "             ('rcv1subset2', 'train'): ['2359343930e2010d0dc90b904430370c',\n",
       "              'rcv1subset2-train.scikitml.bz2'],\n",
       "             ('rcv1subset3', 'undivided'): ['2b2381df4801f4045df907e1ddac8238',\n",
       "              'rcv1subset3-undivided.scikitml.bz2'],\n",
       "             ('rcv1subset3', 'test'): ['e60511202e5688648205200477176f70',\n",
       "              'rcv1subset3-test.scikitml.bz2'],\n",
       "             ('rcv1subset3', 'train'): ['643b3d0a393d72ccd5e80e3ce97343ec',\n",
       "              'rcv1subset3-train.scikitml.bz2'],\n",
       "             ('rcv1subset4', 'undivided'): ['d28954a8d716de4d636600e80e2abb68',\n",
       "              'rcv1subset4-undivided.scikitml.bz2'],\n",
       "             ('rcv1subset4', 'test'): ['2a479638c7e4f280cb230d5bdb2365a8',\n",
       "              'rcv1subset4-test.scikitml.bz2'],\n",
       "             ('rcv1subset4', 'train'): ['a0a1ed6c94157cfe4722d351937abc8f',\n",
       "              'rcv1subset4-train.scikitml.bz2'],\n",
       "             ('rcv1subset5', 'undivided'): ['287a07504a8e6f9b61991d99d04cb7f8',\n",
       "              'rcv1subset5-undivided.scikitml.bz2'],\n",
       "             ('rcv1subset5', 'test'): ['6ab3fd6456d297b919e94a36d7754b85',\n",
       "              'rcv1subset5-test.scikitml.bz2'],\n",
       "             ('rcv1subset5', 'train'): ['b2c69f099486b0f39ed8630f20eba2d5',\n",
       "              'rcv1subset5-train.scikitml.bz2'],\n",
       "             ('scene', 'undivided'): ['627fad77dd17b7b236b6561c18457e5e',\n",
       "              'scene-undivided.scikitml.bz2'],\n",
       "             ('scene', 'test'): ['7e03886ed1c8a49cdb552c89ecb7185f',\n",
       "              'scene-test.scikitml.bz2'],\n",
       "             ('scene', 'train'): ['49a1866da9a56125dd32fc3ce0eeacf9',\n",
       "              'scene-train.scikitml.bz2'],\n",
       "             ('tmc2007_500', 'undivided'): ['963b8594395f5c0eec128b029dd2035a',\n",
       "              'tmc2007_500-undivided.scikitml.bz2'],\n",
       "             ('tmc2007_500', 'test'): ['1a17737bfe8cb24a9a8b487a443e68f2',\n",
       "              'tmc2007_500-test.scikitml.bz2'],\n",
       "             ('tmc2007_500', 'train'): ['93d50cff83fecade6991b2882ced553a',\n",
       "              'tmc2007_500-train.scikitml.bz2'],\n",
       "             ('yeast', 'undivided'): ['81996c76ec858ae4343f6f33ea1f0504',\n",
       "              'yeast-undivided.scikitml.bz2'],\n",
       "             ('yeast', 'test'): ['d868f6ea5f0c2b78a96477c6722fee13',\n",
       "              'yeast-test.scikitml.bz2'],\n",
       "             ('yeast', 'train'): ['90be9e0e636b624269794865e82c2667',\n",
       "              'yeast-train.scikitml.bz2']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene:train - does not exists downloading\n",
      "Downloaded scene-train\n",
      "scene:test - does not exists downloading\n",
      "Downloaded scene-test\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, feature_names, label_names = load_dataset(\"scene\", \"train\")\n",
    "X_test, y_test, _, _ = load_dataset(\"scene\", \"test\")\n",
    "\n",
    "# using `scene` as this dataset seems to be a little bit more comprehensible than the others I tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Att1', 'NUMERIC'),\n",
       " ('Att2', 'NUMERIC'),\n",
       " ('Att3', 'NUMERIC'),\n",
       " ('Att4', 'NUMERIC'),\n",
       " ('Att5', 'NUMERIC'),\n",
       " ('Att6', 'NUMERIC'),\n",
       " ('Att7', 'NUMERIC'),\n",
       " ('Att8', 'NUMERIC'),\n",
       " ('Att9', 'NUMERIC'),\n",
       " ('Att10', 'NUMERIC'),\n",
       " ('Att11', 'NUMERIC'),\n",
       " ('Att12', 'NUMERIC'),\n",
       " ('Att13', 'NUMERIC'),\n",
       " ('Att14', 'NUMERIC'),\n",
       " ('Att15', 'NUMERIC'),\n",
       " ('Att16', 'NUMERIC'),\n",
       " ('Att17', 'NUMERIC'),\n",
       " ('Att18', 'NUMERIC'),\n",
       " ('Att19', 'NUMERIC'),\n",
       " ('Att20', 'NUMERIC'),\n",
       " ('Att21', 'NUMERIC'),\n",
       " ('Att22', 'NUMERIC'),\n",
       " ('Att23', 'NUMERIC'),\n",
       " ('Att24', 'NUMERIC'),\n",
       " ('Att25', 'NUMERIC'),\n",
       " ('Att26', 'NUMERIC'),\n",
       " ('Att27', 'NUMERIC'),\n",
       " ('Att28', 'NUMERIC'),\n",
       " ('Att29', 'NUMERIC'),\n",
       " ('Att30', 'NUMERIC'),\n",
       " ('Att31', 'NUMERIC'),\n",
       " ('Att32', 'NUMERIC'),\n",
       " ('Att33', 'NUMERIC'),\n",
       " ('Att34', 'NUMERIC'),\n",
       " ('Att35', 'NUMERIC'),\n",
       " ('Att36', 'NUMERIC'),\n",
       " ('Att37', 'NUMERIC'),\n",
       " ('Att38', 'NUMERIC'),\n",
       " ('Att39', 'NUMERIC'),\n",
       " ('Att40', 'NUMERIC'),\n",
       " ('Att41', 'NUMERIC'),\n",
       " ('Att42', 'NUMERIC'),\n",
       " ('Att43', 'NUMERIC'),\n",
       " ('Att44', 'NUMERIC'),\n",
       " ('Att45', 'NUMERIC'),\n",
       " ('Att46', 'NUMERIC'),\n",
       " ('Att47', 'NUMERIC'),\n",
       " ('Att48', 'NUMERIC'),\n",
       " ('Att49', 'NUMERIC'),\n",
       " ('Att50', 'NUMERIC'),\n",
       " ('Att51', 'NUMERIC'),\n",
       " ('Att52', 'NUMERIC'),\n",
       " ('Att53', 'NUMERIC'),\n",
       " ('Att54', 'NUMERIC'),\n",
       " ('Att55', 'NUMERIC'),\n",
       " ('Att56', 'NUMERIC'),\n",
       " ('Att57', 'NUMERIC'),\n",
       " ('Att58', 'NUMERIC'),\n",
       " ('Att59', 'NUMERIC'),\n",
       " ('Att60', 'NUMERIC'),\n",
       " ('Att61', 'NUMERIC'),\n",
       " ('Att62', 'NUMERIC'),\n",
       " ('Att63', 'NUMERIC'),\n",
       " ('Att64', 'NUMERIC'),\n",
       " ('Att65', 'NUMERIC'),\n",
       " ('Att66', 'NUMERIC'),\n",
       " ('Att67', 'NUMERIC'),\n",
       " ('Att68', 'NUMERIC'),\n",
       " ('Att69', 'NUMERIC'),\n",
       " ('Att70', 'NUMERIC'),\n",
       " ('Att71', 'NUMERIC'),\n",
       " ('Att72', 'NUMERIC'),\n",
       " ('Att73', 'NUMERIC'),\n",
       " ('Att74', 'NUMERIC'),\n",
       " ('Att75', 'NUMERIC'),\n",
       " ('Att76', 'NUMERIC'),\n",
       " ('Att77', 'NUMERIC'),\n",
       " ('Att78', 'NUMERIC'),\n",
       " ('Att79', 'NUMERIC'),\n",
       " ('Att80', 'NUMERIC'),\n",
       " ('Att81', 'NUMERIC'),\n",
       " ('Att82', 'NUMERIC'),\n",
       " ('Att83', 'NUMERIC'),\n",
       " ('Att84', 'NUMERIC'),\n",
       " ('Att85', 'NUMERIC'),\n",
       " ('Att86', 'NUMERIC'),\n",
       " ('Att87', 'NUMERIC'),\n",
       " ('Att88', 'NUMERIC'),\n",
       " ('Att89', 'NUMERIC'),\n",
       " ('Att90', 'NUMERIC'),\n",
       " ('Att91', 'NUMERIC'),\n",
       " ('Att92', 'NUMERIC'),\n",
       " ('Att93', 'NUMERIC'),\n",
       " ('Att94', 'NUMERIC'),\n",
       " ('Att95', 'NUMERIC'),\n",
       " ('Att96', 'NUMERIC'),\n",
       " ('Att97', 'NUMERIC'),\n",
       " ('Att98', 'NUMERIC'),\n",
       " ('Att99', 'NUMERIC'),\n",
       " ('Att100', 'NUMERIC'),\n",
       " ('Att101', 'NUMERIC'),\n",
       " ('Att102', 'NUMERIC'),\n",
       " ('Att103', 'NUMERIC'),\n",
       " ('Att104', 'NUMERIC'),\n",
       " ('Att105', 'NUMERIC'),\n",
       " ('Att106', 'NUMERIC'),\n",
       " ('Att107', 'NUMERIC'),\n",
       " ('Att108', 'NUMERIC'),\n",
       " ('Att109', 'NUMERIC'),\n",
       " ('Att110', 'NUMERIC'),\n",
       " ('Att111', 'NUMERIC'),\n",
       " ('Att112', 'NUMERIC'),\n",
       " ('Att113', 'NUMERIC'),\n",
       " ('Att114', 'NUMERIC'),\n",
       " ('Att115', 'NUMERIC'),\n",
       " ('Att116', 'NUMERIC'),\n",
       " ('Att117', 'NUMERIC'),\n",
       " ('Att118', 'NUMERIC'),\n",
       " ('Att119', 'NUMERIC'),\n",
       " ('Att120', 'NUMERIC'),\n",
       " ('Att121', 'NUMERIC'),\n",
       " ('Att122', 'NUMERIC'),\n",
       " ('Att123', 'NUMERIC'),\n",
       " ('Att124', 'NUMERIC'),\n",
       " ('Att125', 'NUMERIC'),\n",
       " ('Att126', 'NUMERIC'),\n",
       " ('Att127', 'NUMERIC'),\n",
       " ('Att128', 'NUMERIC'),\n",
       " ('Att129', 'NUMERIC'),\n",
       " ('Att130', 'NUMERIC'),\n",
       " ('Att131', 'NUMERIC'),\n",
       " ('Att132', 'NUMERIC'),\n",
       " ('Att133', 'NUMERIC'),\n",
       " ('Att134', 'NUMERIC'),\n",
       " ('Att135', 'NUMERIC'),\n",
       " ('Att136', 'NUMERIC'),\n",
       " ('Att137', 'NUMERIC'),\n",
       " ('Att138', 'NUMERIC'),\n",
       " ('Att139', 'NUMERIC'),\n",
       " ('Att140', 'NUMERIC'),\n",
       " ('Att141', 'NUMERIC'),\n",
       " ('Att142', 'NUMERIC'),\n",
       " ('Att143', 'NUMERIC'),\n",
       " ('Att144', 'NUMERIC'),\n",
       " ('Att145', 'NUMERIC'),\n",
       " ('Att146', 'NUMERIC'),\n",
       " ('Att147', 'NUMERIC'),\n",
       " ('Att148', 'NUMERIC'),\n",
       " ('Att149', 'NUMERIC'),\n",
       " ('Att150', 'NUMERIC'),\n",
       " ('Att151', 'NUMERIC'),\n",
       " ('Att152', 'NUMERIC'),\n",
       " ('Att153', 'NUMERIC'),\n",
       " ('Att154', 'NUMERIC'),\n",
       " ('Att155', 'NUMERIC'),\n",
       " ('Att156', 'NUMERIC'),\n",
       " ('Att157', 'NUMERIC'),\n",
       " ('Att158', 'NUMERIC'),\n",
       " ('Att159', 'NUMERIC'),\n",
       " ('Att160', 'NUMERIC'),\n",
       " ('Att161', 'NUMERIC'),\n",
       " ('Att162', 'NUMERIC'),\n",
       " ('Att163', 'NUMERIC'),\n",
       " ('Att164', 'NUMERIC'),\n",
       " ('Att165', 'NUMERIC'),\n",
       " ('Att166', 'NUMERIC'),\n",
       " ('Att167', 'NUMERIC'),\n",
       " ('Att168', 'NUMERIC'),\n",
       " ('Att169', 'NUMERIC'),\n",
       " ('Att170', 'NUMERIC'),\n",
       " ('Att171', 'NUMERIC'),\n",
       " ('Att172', 'NUMERIC'),\n",
       " ('Att173', 'NUMERIC'),\n",
       " ('Att174', 'NUMERIC'),\n",
       " ('Att175', 'NUMERIC'),\n",
       " ('Att176', 'NUMERIC'),\n",
       " ('Att177', 'NUMERIC'),\n",
       " ('Att178', 'NUMERIC'),\n",
       " ('Att179', 'NUMERIC'),\n",
       " ('Att180', 'NUMERIC'),\n",
       " ('Att181', 'NUMERIC'),\n",
       " ('Att182', 'NUMERIC'),\n",
       " ('Att183', 'NUMERIC'),\n",
       " ('Att184', 'NUMERIC'),\n",
       " ('Att185', 'NUMERIC'),\n",
       " ('Att186', 'NUMERIC'),\n",
       " ('Att187', 'NUMERIC'),\n",
       " ('Att188', 'NUMERIC'),\n",
       " ('Att189', 'NUMERIC'),\n",
       " ('Att190', 'NUMERIC'),\n",
       " ('Att191', 'NUMERIC'),\n",
       " ('Att192', 'NUMERIC'),\n",
       " ('Att193', 'NUMERIC'),\n",
       " ('Att194', 'NUMERIC'),\n",
       " ('Att195', 'NUMERIC'),\n",
       " ('Att196', 'NUMERIC'),\n",
       " ('Att197', 'NUMERIC'),\n",
       " ('Att198', 'NUMERIC'),\n",
       " ('Att199', 'NUMERIC'),\n",
       " ('Att200', 'NUMERIC'),\n",
       " ('Att201', 'NUMERIC'),\n",
       " ('Att202', 'NUMERIC'),\n",
       " ('Att203', 'NUMERIC'),\n",
       " ('Att204', 'NUMERIC'),\n",
       " ('Att205', 'NUMERIC'),\n",
       " ('Att206', 'NUMERIC'),\n",
       " ('Att207', 'NUMERIC'),\n",
       " ('Att208', 'NUMERIC'),\n",
       " ('Att209', 'NUMERIC'),\n",
       " ('Att210', 'NUMERIC'),\n",
       " ('Att211', 'NUMERIC'),\n",
       " ('Att212', 'NUMERIC'),\n",
       " ('Att213', 'NUMERIC'),\n",
       " ('Att214', 'NUMERIC'),\n",
       " ('Att215', 'NUMERIC'),\n",
       " ('Att216', 'NUMERIC'),\n",
       " ('Att217', 'NUMERIC'),\n",
       " ('Att218', 'NUMERIC'),\n",
       " ('Att219', 'NUMERIC'),\n",
       " ('Att220', 'NUMERIC'),\n",
       " ('Att221', 'NUMERIC'),\n",
       " ('Att222', 'NUMERIC'),\n",
       " ('Att223', 'NUMERIC'),\n",
       " ('Att224', 'NUMERIC'),\n",
       " ('Att225', 'NUMERIC'),\n",
       " ('Att226', 'NUMERIC'),\n",
       " ('Att227', 'NUMERIC'),\n",
       " ('Att228', 'NUMERIC'),\n",
       " ('Att229', 'NUMERIC'),\n",
       " ('Att230', 'NUMERIC'),\n",
       " ('Att231', 'NUMERIC'),\n",
       " ('Att232', 'NUMERIC'),\n",
       " ('Att233', 'NUMERIC'),\n",
       " ('Att234', 'NUMERIC'),\n",
       " ('Att235', 'NUMERIC'),\n",
       " ('Att236', 'NUMERIC'),\n",
       " ('Att237', 'NUMERIC'),\n",
       " ('Att238', 'NUMERIC'),\n",
       " ('Att239', 'NUMERIC'),\n",
       " ('Att240', 'NUMERIC'),\n",
       " ('Att241', 'NUMERIC'),\n",
       " ('Att242', 'NUMERIC'),\n",
       " ('Att243', 'NUMERIC'),\n",
       " ('Att244', 'NUMERIC'),\n",
       " ('Att245', 'NUMERIC'),\n",
       " ('Att246', 'NUMERIC'),\n",
       " ('Att247', 'NUMERIC'),\n",
       " ('Att248', 'NUMERIC'),\n",
       " ('Att249', 'NUMERIC'),\n",
       " ('Att250', 'NUMERIC'),\n",
       " ('Att251', 'NUMERIC'),\n",
       " ('Att252', 'NUMERIC'),\n",
       " ('Att253', 'NUMERIC'),\n",
       " ('Att254', 'NUMERIC'),\n",
       " ('Att255', 'NUMERIC'),\n",
       " ('Att256', 'NUMERIC'),\n",
       " ('Att257', 'NUMERIC'),\n",
       " ('Att258', 'NUMERIC'),\n",
       " ('Att259', 'NUMERIC'),\n",
       " ('Att260', 'NUMERIC'),\n",
       " ('Att261', 'NUMERIC'),\n",
       " ('Att262', 'NUMERIC'),\n",
       " ('Att263', 'NUMERIC'),\n",
       " ('Att264', 'NUMERIC'),\n",
       " ('Att265', 'NUMERIC'),\n",
       " ('Att266', 'NUMERIC'),\n",
       " ('Att267', 'NUMERIC'),\n",
       " ('Att268', 'NUMERIC'),\n",
       " ('Att269', 'NUMERIC'),\n",
       " ('Att270', 'NUMERIC'),\n",
       " ('Att271', 'NUMERIC'),\n",
       " ('Att272', 'NUMERIC'),\n",
       " ('Att273', 'NUMERIC'),\n",
       " ('Att274', 'NUMERIC'),\n",
       " ('Att275', 'NUMERIC'),\n",
       " ('Att276', 'NUMERIC'),\n",
       " ('Att277', 'NUMERIC'),\n",
       " ('Att278', 'NUMERIC'),\n",
       " ('Att279', 'NUMERIC'),\n",
       " ('Att280', 'NUMERIC'),\n",
       " ('Att281', 'NUMERIC'),\n",
       " ('Att282', 'NUMERIC'),\n",
       " ('Att283', 'NUMERIC'),\n",
       " ('Att284', 'NUMERIC'),\n",
       " ('Att285', 'NUMERIC'),\n",
       " ('Att286', 'NUMERIC'),\n",
       " ('Att287', 'NUMERIC'),\n",
       " ('Att288', 'NUMERIC'),\n",
       " ('Att289', 'NUMERIC'),\n",
       " ('Att290', 'NUMERIC'),\n",
       " ('Att291', 'NUMERIC'),\n",
       " ('Att292', 'NUMERIC'),\n",
       " ('Att293', 'NUMERIC'),\n",
       " ('Att294', 'NUMERIC')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beach', ['0', '1']),\n",
       " ('Sunset', ['0', '1']),\n",
       " ('FallFoliage', ['0', '1']),\n",
       " ('Field', ['0', '1']),\n",
       " ('Mountain', ['0', '1']),\n",
       " ('Urban', ['0', '1'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `scene` as this dataset seems to be a little bit more comprehensible than the others I tested.\n",
    "\n",
    "For more information regarding the datasets and how `scikit-multilearn` handles them, [read this page](http://scikit.ml/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(\n",
    "    classifier=SVC(),\n",
    "    require_dense=[False, True]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(), require_dense=[False, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beach', ['0', '1']),\n",
       " ('Sunset', ['0', '1']),\n",
       " ('FallFoliage', ['0', '1']),\n",
       " ('Field', ['0', '1']),\n",
       " ('Mountain', ['0', '1']),\n",
       " ('Urban', ['0', '1'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c7d288e37b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregular_br_hamming_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhamming_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mregular_br_hamming_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "regular_br_hamming_loss = metrics.hamming_loss(y_test, prediction)\n",
    "regular_br_hamming_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5869565217391305"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_br_accuracy_score = metrics.accuracy_score(y_test, prediction)\n",
    "regular_br_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicStacking(ProblemTransformationBase):\n",
    "    first_layer_classifiers: BinaryRelevance\n",
    "    second_layer_classifiers: BinaryRelevance\n",
    "\n",
    "    def __init__(self, classifier: Any = None, require_dense: Optional[List[bool]] = None):\n",
    "        super(BasicStacking, self).__init__(classifier, require_dense)\n",
    "\n",
    "        self.first_layer_classifiers = BinaryRelevance(\n",
    "            classifier=SVC(),\n",
    "            require_dense=[False, True]\n",
    "        )\n",
    "\n",
    "        self.second_layer_classifiers = BinaryRelevance(\n",
    "            classifier=SVC(),\n",
    "            require_dense=[False, True]\n",
    "        )\n",
    "    \n",
    "    def fit(self, X: Any, y: Any):\n",
    "        self.first_layer_classifiers.fit(X, y)\n",
    "\n",
    "        first_layer_predictions = self.first_layer_classifiers.predict(X)\n",
    "        X_expanded = np.hstack([X.todense(), first_layer_predictions.todense()])\n",
    "\n",
    "        self.second_layer_classifiers.fit(X_expanded, y)\n",
    "    \n",
    "    def predict(self, X: Any):\n",
    "        first_layer_predictions = self.first_layer_classifiers.predict(X)\n",
    "        X_expanded = np.hstack([X.todense(), first_layer_predictions.todense()])\n",
    "        return self.second_layer_classifiers.predict(X_expanded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.646467 0.666435 0.685047 ... 0.       0.       0.      ]\n",
      " [0.770156 0.767255 0.761053 ... 0.       0.       0.      ]\n",
      " [0.793984 0.772096 0.76182  ... 0.       0.       0.      ]\n",
      " ...\n",
      " [0.85639  1.       1.       ... 0.       0.       0.      ]\n",
      " [0.805592 0.80417  0.811438 ... 0.       0.       1.      ]\n",
      " [0.855064 0.858896 0.911177 ... 0.       0.       1.      ]]\n"
     ]
    }
   ],
   "source": [
    "model = BasicStacking()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br hamming_loss 0.08416945373467112\n",
      "br accuracy 0.5869565217391305\n",
      "===\n",
      "stacking hamming_loss 0.08416945373467112\n",
      "stacking accuracy 0.5869565217391305\n"
     ]
    }
   ],
   "source": [
    "stacking_hamming_loss = metrics.hamming_loss(y_test, stacking_prediction)\n",
    "stacking_accuracy_score = metrics.accuracy_score(y_test, stacking_prediction)\n",
    "\n",
    "print(\"br hamming_loss\", regular_br_hamming_loss)\n",
    "print(\"br accuracy\", regular_br_accuracy_score)\n",
    "print(\"===\")\n",
    "print(\"stacking hamming_loss\", stacking_hamming_loss)\n",
    "print(\"stacking accuracy\", stacking_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Both the Binary Relevance and the Stacking approaches resulted in the exact same performance.\n",
    "\n",
    "Possibilites:\n",
    "* The stacking implementation is wrong.\n",
    "  * To test this, we have to review the code and compare it to other stacking implementations; for instance: the stacking implementation in the `utiml` library for R.\n",
    "* The stacking implementation is correct, but the labels are not correlated at all, meaning that the stacking approach is not useful.\n",
    "  * To test this, we have to check other datasets and see if the stacking approach is useful in those cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Comparing to other stacking implementations\n",
    "\n",
    "Let's compare my implementation of the stacking classifier to the one from [utiml](https://github.com/rivolli/utiml).\n",
    "\n",
    "[Here is a guide](https://cran.r-project.org/web/packages/utiml/vignettes/utiml-overview.html) to get started with the `utiml` library.\n",
    "\n",
    "2023-08-17: I tried to read the source code, but I could not spot exactly how the stacking is being implemented. As a matter of fact, I don't even know if my understanding of the stacking is correct.\n",
    "\n",
    "For now, I will proceed with implementing the actual model, and then I will try to go back and debug all of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Using other datasets\n",
    "\n",
    "I will try to list all available datasets, then try all of them using Binary Relevance as a baseline and my Basic Stacking approach. The objective is to see if the performance metrics change for any of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SplitDataset = Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
    "\n",
    "class BasicStackingAgainstBinaryRelevanceBaselineTest:\n",
    "    def run(self):\n",
    "        results = []\n",
    "\n",
    "        for name in self.get_unique_available_data_set_names():\n",
    "            data_sets = self.get_data_set(name)\n",
    "\n",
    "            baseline_metrics = self.get_metrics_for_baseline_model(data_sets)\n",
    "            stacking_metrics = self.get_metrics_for_basic_stacking(data_sets)\n",
    "\n",
    "            results.append({\n",
    "                \"dataset_name\": name,\n",
    "                \"baseline_accuracy\": baseline_metrics[0],\n",
    "                \"baseline_hamming_loss\": baseline_metrics[1],\n",
    "                \"stacking_accuracy\": stacking_metrics[0],\n",
    "                \"stacking_hamming_loss\": stacking_metrics[1]\n",
    "            })\n",
    "\n",
    "            self.save_results(results)\n",
    "            print(f\"finished baseline for {name}\")\n",
    "\n",
    "    def get_metrics_for_baseline_model(self, split_dataset: SplitDataset) -> Tuple[float, float]:\n",
    "        clf = BinaryRelevance(\n",
    "            classifier=SVC(),\n",
    "            require_dense=[False, True]\n",
    "        )\n",
    "        return self.get_metrics_for_model(clf, split_dataset)\n",
    "\n",
    "    def get_metrics_for_basic_stacking(self, split_dataset: SplitDataset) -> Tuple[float, float]:\n",
    "        clf = BasicStacking()\n",
    "        return self.get_metrics_for_model(clf, split_dataset)\n",
    "\n",
    "    def get_metrics_for_model(self, clf: Any, split_dataset: SplitDataset) -> Tuple[float, float]:\n",
    "        X_train, y_train, X_test, y_test = split_dataset\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        prediction = clf.predict(X_test)\n",
    "        accuracy_score = metrics.accuracy_score(y_test, prediction)\n",
    "        hamming_loss = metrics.hamming_loss(y_test, prediction)\n",
    "\n",
    "        return accuracy_score, hamming_loss\n",
    "\n",
    "    def save_results(self, results: List[Dict[str, Any]]):\n",
    "        with open(\"results.json\", \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "\n",
    "    def get_unique_available_data_set_names(self) -> List[str]:\n",
    "        dataset_names = []\n",
    "\n",
    "        _available_data_sets = available_data_sets()\n",
    "        if _available_data_sets is None:\n",
    "            raise Exception(\"could not load available data sets\")\n",
    "\n",
    "        skip = [\"bibtex\", \"Corel5k\", \"delicious\", \"enron\", \"genbase\", \"mediamill\"]\n",
    "        # bibtex -> takes too long to train and test\n",
    "        # Corel5k -> apparently it has only a single class, which is not accepted by the classifier\n",
    "        # delicious -> takes too long to train and test\n",
    "        # enron -> apparently it has only a single class, which is not accepted by the classifier\n",
    "        # genbase -> apparently it has only a single class, which is not accepted by the classifier\n",
    "        # mediamill -> takes too long to train and test\n",
    "\n",
    "        for dataset_name, variant in _available_data_sets:\n",
    "            if dataset_name in skip:\n",
    "                continue\n",
    "\n",
    "            if dataset_name not in dataset_names:\n",
    "                dataset_names.append(dataset_name)\n",
    "\n",
    "        return dataset_names\n",
    "\n",
    "    def get_data_set(self, name: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        train_data = load_dataset(name, \"train\")\n",
    "        if train_data is None:\n",
    "            raise Exception(f\"could not load data set {name}\")\n",
    "\n",
    "        test_data = load_dataset(name, \"test\")\n",
    "        if test_data is None:\n",
    "            raise Exception(f\"could not load data set {name}\")\n",
    "        \n",
    "        X_train, y_train, _, _ = train_data\n",
    "        X_test, y_test, _, _ = test_data\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "# using `scene` as this dataset seems to be a little bit more comprehensible than the others I tested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "birds:train - exists, not redownloading\n",
      "birds:test - exists, not redownloading\n",
      "finished baseline for birds\n",
      "emotions:train - exists, not redownloading\n",
      "emotions:test - exists, not redownloading\n",
      "finished baseline for emotions\n",
      "mediamill:train - exists, not redownloading\n",
      "mediamill:test - exists, not redownloading\n"
     ]
    }
   ],
   "source": [
    "pipeline = BasicStackingAgainstBinaryRelevanceBaselineTest()\n",
    "pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
